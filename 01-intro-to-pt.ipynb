{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38664bitlotteryce31c0a482d54873875cc8eb2d66ce61",
   "display_name": "Python 3.8.6 64-bit ('lottery')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Deep Learning Course - LAB 1\n",
    "\n",
    "## Intro to PyTorch\n",
    "\n",
    "PyTorch (PT) is a Python (and C++) library for Machine Learning (ML) particularly suited for Neural Networks and their applications.\n",
    "\n",
    "Its great selection of built-in modules, models, and functions, CUDA capability, tensor arithmetic support and automatic differentiation functionality make it one of the most used scientific libraries for Deep Learning."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Installing PyTorch\n",
    "\n",
    "We advise to install PyTorch following the directions given in its [home page](https://pytorch.org/get-started/locally/). Just typing `pip install torch` may not be the correct action as you have to take into account the compatibility with `cuda`. If you have `cuda` installed, you can find your version by typing `nvcc --version` in a terminal (Linux/iOS). \n",
    "\n",
    "If you're using Windows, we first suggest first to install Anaconda and then install PyTorch from the `anaconda prompt` software via `conda` (preferably) or `pip`.\n",
    "\n",
    "If you're using Google Colab, all the libraries needed to follow this lecture should be pre-installed there.\n",
    "\n",
    "We see now how to operate on Colab."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### For Colab users\n",
    "\n",
    "Google Colab is a handy tool that we suggest you use for this course---especially if your laptop does not support CUDA or has limited hardware capabilities. Anyway, note that **we'll try to avoid GPU code as much as possible**.\n",
    "\n",
    "Essentially, Colab renders available to you a virtual machine with a limited hardware capability and disk where you can execute your code inside a given time window. You can even ask for a GPU (if you use it too much you'll need to start waiting a lot before it's available though)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Your (maybe) first Colab commands\n",
    "\n",
    "Colab Jupyter-style notebook interface with a few tweaks.\n",
    "\n",
    "For instance, you may run (some) bash command from here prepending `!` to your code."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/mnzluca/IntroToAI"
   ]
  },
  {
   "source": [
    "This makes it very easy to operate your virtual machine without the need for a terminal. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### File transfer on Colab\n",
    "\n",
    "One of the most intricate action in Colab is file transfer. Since your files reside on the virtual machine, there're two main ways to operate file transfer on Colab.\n",
    "\n",
    "* `files.download()` / `.upload()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-aa0b74424143>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sample_data/README.md\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "files.download(\"sample_data/README.md\")"
   ]
  },
  {
   "source": [
    "Although it may be much more handy to connect your Google Drive to Colab. Here is a snippet that lets you do this."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "folder_mount = '/content/drive' # Your Drive will be mounted on top of this path\n",
    "\n",
    "drive.mount(folder_mount)"
   ]
  },
  {
   "source": [
    "### Dive into PyTorch - connections with NumPy\n",
    "\n",
    "Like NumPy, PyTorch provides its own multidimensional array class, called `Tensor`. `Tensor`s are essentially the equivalent of NumPy `ndarray`s.\n",
    "If we wish to operate a very superficial comparison between `Tensor` and `ndarray`, we can say that:\n",
    "* `Tensor` draws a lot of methods from NumPy, although it's missing some (see [this GitHub issue](if you're interested))\n",
    "* `Tensor` is more OO than `ndarray` and solves some inconsistencies within NumPy\n",
    "* `Tensor` has CUDA support"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x\ntensor([[1., 5., 4.],\n        [3., 2., 1.]])\n\n\ny\n[[1 5 4]\n [3 2 1]]\n\n\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# create custom Tensor and ndarray\n",
    "x = torch.Tensor([[1,5,4],[3,2,1]])\n",
    "y = np.array([[1,5,4],[3,2,1]])\n",
    "\n",
    "def pretty_print(obj, title=None):\n",
    "    if title is not None:\n",
    "        print(title)\n",
    "    print(obj)\n",
    "    print(\"\\n\")\n",
    "\n",
    "pretty_print(x, \"x\")\n",
    "pretty_print(y, \"y\")"
   ]
  },
  {
   "source": [
    "What are the types of these objs?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.float32, dtype('int32'))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "source": [
    "`torch` already thinks with Machine Learning in mind as the `Tensor` is implicitly converted to `dtype float32`, while NumPy makes no such assumption.ù\n",
    "\n",
    "As in NumPy, we can call the `.shape` attribute to get the shape of the structures. Moreover, `Tensor`s have also the `.size()` method which is analogous to `.shape`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), (2, 3), torch.Size([2, 3]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "x.shape, y.shape, x.size()"
   ]
  },
  {
   "source": [
    "Notice how a `Tensor` shape is **not** a tuple.\n",
    "\n",
    "We can also create a random `Tensor` analogously to NumPy.\n",
    "\n",
    "A `2 × 3 × 3` `Tensor` is the same as saying \"2 3 × 3 matrices\", or a \"cubic matrix\"\n",
    "\n",
    "![](img/tensors.jpg)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.9075, 0.3282, 0.6428],\n",
       "         [0.1238, 0.5174, 0.7906],\n",
       "         [0.4972, 0.0083, 0.9456]],\n",
       "\n",
       "        [[0.0233, 0.0804, 0.1670],\n",
       "         [0.6405, 0.3106, 0.9403],\n",
       "         [0.0926, 0.2227, 0.2389]]])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "x = torch.rand([2, 3, 3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[0.41036214, 0.28587342, 0.91145268],\n",
       "        [0.15027504, 0.45377417, 0.55654618],\n",
       "        [0.20955594, 0.72104528, 0.22529777]],\n",
       "\n",
       "       [[0.95001789, 0.29200055, 0.16068889],\n",
       "        [0.79229758, 0.18374119, 0.51103874],\n",
       "        [0.38043905, 0.65597989, 0.78787944]]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "y = np.random.rand(2, 3, 3)\n",
    "y"
   ]
  },
  {
   "source": [
    "#### Slicing a `Tensor`\n",
    "\n",
    "You can slice a `Tensor` (*i.e.*, extract a substructure of a `Tensor`) as in NumPy using the square brackets:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Slice first element\ntensor([[0.9075, 0.3282, 0.6428],\n        [0.1238, 0.5174, 0.7906],\n        [0.4972, 0.0083, 0.9456]])\n\n\nSlice element at (0, 1, 2)\ntensor(0.0926)\n\n\nSlice first element of second dim\ntensor([[0.9075, 0.3282, 0.6428],\n        [0.0233, 0.0804, 0.1670]])\n\n\nAs above\ntensor([[0.9075, 0.3282, 0.6428],\n        [0.0233, 0.0804, 0.1670]])\n\n\nSlice first and second el of third dim\ntensor([[[0.9075, 0.3282],\n         [0.1238, 0.5174],\n         [0.4972, 0.0083]],\n\n        [[0.0233, 0.0804],\n         [0.6405, 0.3106],\n         [0.0926, 0.2227]]])\n\n\nAs above\ntensor([[[0.9075, 0.3282],\n         [0.1238, 0.5174],\n         [0.4972, 0.0083]],\n\n        [[0.0233, 0.0804],\n         [0.6405, 0.3106],\n         [0.0926, 0.2227]]])\n\n\n"
     ]
    }
   ],
   "source": [
    "# extract first element (i.e., matrix) of first dimension\n",
    "pretty_print(x[0], \"Slice first element\")\n",
    "\n",
    "# extract a specific element\n",
    "pretty_print(x[1,2,0], \"Slice element at (0, 1, 2)\")\n",
    "\n",
    "# extract first element of second dimension (\":\" means all the elements of the given dim)\n",
    "pretty_print(x[:, 0], \"Slice first element of second dim\")\n",
    "\n",
    "# note that it is equivalent to\n",
    "pretty_print(x[:, 0, :], \"As above\")\n",
    "\n",
    "# extract range of dimensions (first and second element of third dim) \n",
    "pretty_print(x[:, :, 0:2], \"Slice first and second el of third dim\")\n",
    "\n",
    "# note that it is equivalent to (i.e., you can also pass list for slicing, as opposed to Py vanilla lists/tuples)\n",
    "pretty_print(x[:, :, (0, 1)], \"As above\")"
   ]
  },
  {
   "source": [
    "In Py, you can also slice any list by interval via the \"double colon\" notation `::` (`from`:`to - 1`:`step`). Note that `::3` means \"take all elements of the object by step of 3 starting from 0 until the list ends\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 3., 6.])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "torch.range(0, 10)[0:7:3]"
   ]
  },
  {
   "source": [
    "#### `Tensor` supports linear algebra"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "z1\ntorch.Size([4, 5])\ntensor([[0.6182, 0.8421, 0.5606, 0.5392, 0.4711],\n        [0.2708, 0.9917, 0.0571, 0.7530, 0.7690],\n        [0.0237, 0.1496, 0.9775, 0.4337, 0.0743],\n        [0.0614, 0.2610, 0.9684, 0.8846, 0.8239]])\n\nz2\ntorch.Size([5, 4])\ntensor([[0.6182, 0.2708, 0.0237, 0.0614],\n        [0.8421, 0.9917, 0.1496, 0.2610],\n        [0.5606, 0.0571, 0.9775, 0.9684],\n        [0.5392, 0.7530, 0.4337, 0.8846],\n        [0.4711, 0.7690, 0.0743, 0.8239]])\n"
     ]
    }
   ],
   "source": [
    "z1 = torch.rand([4, 5])\n",
    "print(\"z1\")\n",
    "print(z1.shape)\n",
    "print(z1)\n",
    "\n",
    "# transposition\n",
    "z2 = z1.T\n",
    "\n",
    "print(\"\\nz2\")\n",
    "print(z2.shape)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matrix multiplication: with '@`\ntensor([[1.9182, 1.8028, 0.9575, 1.6659],\n        [1.8028, 2.2183, 0.5944, 1.6305],\n        [0.9575, 0.5944, 1.1720, 1.4320],\n        [1.6659, 1.6305, 1.4320, 2.4711]])\n\n\nMatrix multiplication: with torch.matmul\ntensor([[1.9182, 1.8028, 0.9575, 1.6659],\n        [1.8028, 2.2183, 0.5944, 1.6305],\n        [0.9575, 0.5944, 1.1720, 1.4320],\n        [1.6659, 1.6305, 1.4320, 2.4711]])\n\n\nMatrix multiplication: with Tensor.matmul\ntensor([[1.9182, 1.8028, 0.9575, 1.6659],\n        [1.8028, 2.2183, 0.5944, 1.6305],\n        [0.9575, 0.5944, 1.1720, 1.4320],\n        [1.6659, 1.6305, 1.4320, 2.4711]])\n\n\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "pretty_print(z1 @ z2, \"Matrix multiplication: with '@`\")\n",
    "\n",
    "# equivalent to\n",
    "pretty_print(torch.matmul(z1, z2), \"Matrix multiplication: with torch.matmul\")\n",
    "\n",
    "# and also\n",
    "pretty_print(z1.matmul(z2), \"Matrix multiplication: with Tensor.matmul\")"
   ]
  },
  {
   "source": [
    "Note that `@` identifies the matrix product.\n",
    "\n",
    "Don't mistake `@` and `*` as the latter is the Hadamard (element-by-element) product!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-2e428a0c80e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mz2\u001b[0m \u001b[1;31m# this gives an Exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "z1 * z2 # this gives an Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.8051, 0.8918, 0.1943, 0.9058, 0.0430],\n",
       "        [0.1791, 0.0034, 0.7147, 0.8877, 0.1794],\n",
       "        [0.6832, 0.5701, 0.2725, 0.0767, 0.1976],\n",
       "        [0.4425, 0.9179, 0.4899, 0.3608, 0.1656]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "z1 * z1"
   ]
  },
  {
   "source": [
    "Generally, the \"regular\" arithmetic operators for Python act as element-wise operators in `Tensor`s (as in `ndarrays`)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.8051, 0.8918, 0.1943, 0.9058, 0.0430],\n",
       "        [0.1791, 0.0034, 0.7147, 0.8877, 0.1794],\n",
       "        [0.6832, 0.5701, 0.2725, 0.0767, 0.1976],\n",
       "        [0.4425, 0.9179, 0.4899, 0.3608, 0.1656]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "z1 ** 2 # Equivalent to above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "z1 % z3 (remainder of integer division)\ntensor([[ 0.6182,  0.8421,  0.5606,  0.5392,  0.4711],\n        [ 0.0708,  0.9917,  0.0571,  0.7530,  0.7690],\n        [-0.9763,  0.1496, -3.0225,  0.4337,  0.0743],\n        [ 0.0614,  0.2610,  0.9684,  0.8846,  0.8239]])\n\n\nz3 // z1 (integer division)\ntensor([[  1.,   2.,   5.,   7.,  14.],\n        [  0.,   2.,  70.,   6.,   3.],\n        [-42.,  20.,  -4.,   4.,  26.],\n        [ 16.,   3.,   1.,   1.,   2.]])\n\n\nin-place tensor division\ntensor([[  1.6177,   2.3751,   5.3515,   7.4179,  14.8575],\n        [  0.7384,   2.0168,  70.0059,   6.6404,   3.9012],\n        [-42.2678,  20.0486,  -4.0922,   4.6114,  26.9138],\n        [ 16.2813,   3.8308,   1.0326,   1.1304,   2.4276]])\n\n\n"
     ]
    }
   ],
   "source": [
    "z3 = torch.Tensor([[1,2,3,4,7],[0.2,2,4,5,3],[-1,3,-4,2,2],[1,1,1,1,2]])\n",
    "pretty_print(z1 % z3, \"z1 % z3 (remainder of integer division)\")\n",
    "pretty_print(z3 // z1, \"z3 // z1 (integer division)\") # integer division\n",
    "z3 /= z1\n",
    "pretty_print(z3, \"in-place tensor division\")"
   ]
  },
  {
   "source": [
    "As for `ndarrays`, `Tensor`s arithmetic operations support **broadcasting**. Roughly speaking, when two `Tensor`s have different shapes and a binary+ operator is applied to them, PT will try to find a way to make these objects \"compatible\" for the operation. \n",
    "\n",
    "Of course, broadcasting is not always possible, but as a rule of thumb, if some dimensions of a `Tensor` are one and the other dimensions are the same, broadcasting works."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "small_vector_5: tensor([1., 2., 3., 5., 2.]) ; Shape: torch.Size([5]) \n\nBroadcasting: dividing matrix by row vector\ntensor([[0.6182, 0.4210, 0.1869, 0.1078, 0.2356],\n        [0.2708, 0.4958, 0.0190, 0.1506, 0.3845],\n        [0.0237, 0.0748, 0.3258, 0.0867, 0.0372],\n        [0.0614, 0.1305, 0.3228, 0.1769, 0.4119]])\n\n\nsmall_vector_4:\n tensor([[4.],\n        [2.],\n        [3.],\n        [1.]]) \nShape: torch.Size([4, 1]) \n\nBroadcasting: dividing matrix by column vector\ntensor([[0.1545, 0.2105, 0.1401, 0.1348, 0.1178],\n        [0.1354, 0.4958, 0.0286, 0.3765, 0.3845],\n        [0.0079, 0.0499, 0.3258, 0.1446, 0.0248],\n        [0.0614, 0.2610, 0.9684, 0.8846, 0.8239]])\n\n\n"
     ]
    }
   ],
   "source": [
    "small_vector_5 = torch.Tensor([1,2,3,5,2]) # this is treated as a row vector (1 x 5 matrix)\n",
    "print(\"small_vector_5:\", small_vector_5, \"; Shape:\", small_vector_5.shape, \"\\n\")\n",
    "\n",
    "pretty_print(z1 / small_vector_5, \"Broadcasting: dividing matrix by row vector\")\n",
    "\n",
    "small_vector_4 = torch.Tensor([4,2,3,1])\n",
    "small_vector_4 = small_vector_4.unsqueeze(-1) # this operation \"transposes\" the vector into a column vector (4 x 1 matrix)\n",
    "print(\"small_vector_4:\\n\", small_vector_4, \"\\nShape:\", small_vector_4.shape, \"\\n\")\n",
    "\n",
    "pretty_print(z1 / small_vector_4, \"Broadcasting: dividing matrix by column vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[True, True, True]])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "torch.Tensor([1,2,3]) == torch.Tensor([[1,2,3]]) # single-dim Tensors are also row vectors"
   ]
  },
  {
   "source": [
    "We already saw a case of incompatible `Tensor`s above.\n",
    "\n",
    "Some more lineal algebra...\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor norm\ntensor(92.2838)\n\n\nndarray norm\n7.483314773547883\n\n\n"
     ]
    }
   ],
   "source": [
    "z3_norm = z3.norm(2)\n",
    "pretty_print(z3_norm, \"Tensor norm\")\n",
    "pretty_print(np.linalg.norm(y), \"ndarray norm\") # notice how torch is more OO"
   ]
  },
  {
   "source": [
    "Notice how methods reducing `Tensor`s to scalars still return singleton `Tensor`s. (be wary of this feature when scripting something in PT)\n",
    "\n",
    "To \"disentangle\" the scalar from a `Tensor` use the `.item()` method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "51.5969352722168"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "z3_norm.item()"
   ]
  },
  {
   "source": [
    "#### Seamless conversion from NumPy to PT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y converted to torch.Tensor\ntensor([[1, 5, 4],\n        [3, 2, 1]], dtype=torch.int32)\n\n\nx converted to numpy.ndarray\n[[[0.9074899  0.32821608 0.64279073]\n  [0.12377012 0.51739407 0.7906445 ]\n  [0.4972009  0.00826526 0.9455616 ]]\n\n [[0.02333057 0.08041859 0.16697049]\n  [0.6404953  0.3105638  0.9402961 ]\n  [0.09256816 0.222704   0.23891562]]]\n\n\nExample of implicit conversion Tensor → ndarray\n2.221468\n\n\n"
     ]
    }
   ],
   "source": [
    "y_torch = torch.from_numpy(y)\n",
    "pretty_print(y_torch, \"y converted to torch.Tensor\")\n",
    "\n",
    "x_numpy = x.numpy()\n",
    "pretty_print(x_numpy, \"x converted to numpy.ndarray\")\n",
    "\n",
    "# Note that NumPy implicitly converts Tensor to ndarray whenever it can; the same doesn't happen for PT\n",
    "pretty_print(np.linalg.norm(x), \"Example of implicit conversion Tensor → ndarray\")"
   ]
  },
  {
   "source": [
    "#### Stochastic functionalities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(randperm) Random permutation of 0:10\ntensor([4, 7, 2, 6, 1, 9, 8, 0, 5, 3])\n\n\n(rand_like) Create random vector with the same shape of z_1\ntensor([[0.3826, 0.8858, 0.4603, 0.1621, 0.3258],\n        [0.3917, 0.5695, 0.8140, 0.6596, 0.1741],\n        [0.3374, 0.6738, 0.6525, 0.5383, 0.5528],\n        [0.3606, 0.1887, 0.1684, 0.3050, 0.1850]])\n\n\n(randint) Like rand, but with integers up to 10\ntensor([[7, 2, 8],\n        [9, 0, 1],\n        [5, 4, 0]])\n\n\n(normal) Sampling a 3x3 iid scalars from N(0,1)\ntensor([[-0.2917,  0.5465, -2.2633],\n        [ 0.5990,  1.8457,  0.7682],\n        [ 0.6011,  0.8857, -1.0599]])\n\n\nSampling from 9 normals with different means and std into a (3x3) Tensor\ntensor([[ 0.6668,  2.3454,  2.8719],\n        [ 4.7201,  6.2344,  6.3202],\n        [ 4.7931,  5.9379, -1.4390]])\n\n\ntensor([[-0.1114, -3.1255,  3.0000],\n        [ 0.0126, -3.3280,  3.0000],\n        [ 0.0000, -3.0000,  3.9604]])\n\n\n"
     ]
    }
   ],
   "source": [
    "pretty_print(torch.randperm(10), \"(randperm) Random permutation of 0:10\")\n",
    "\n",
    "pretty_print(torch.rand_like(z1), \"(rand_like) Create random vector with the same shape of z_1\")\n",
    "\n",
    "pretty_print(torch.randint(10, (3, 3)), \"(randint) Like rand, but with integers up to 10\")\n",
    "\n",
    "pretty_print(torch.normal(0, 1, (3, 3)), \"(normal) Sampling a 3x3 iid scalars from N(0,1)\")\n",
    "\n",
    "pretty_print(torch.normal(torch.Tensor([[1,2,3],[4,5,6],[0,0,0]]), torch.Tensor([[1,0.5,0.9],[0.5,1,0.1],[3,4,1]])), \"Sampling from 9 normals with different means and std into a (3x3) Tensor\")"
   ]
  },
  {
   "source": [
    "### Using GPUs\n",
    "\n",
    "All `Torch.Tensor` methods support GPU computation via built-in CUDA wrappers.\n",
    "\n",
    "Just transfer the involved `Tensor`s to CUDA and let the magic happen :)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "# check if cuda is available on this machine\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "dim = 10000\n",
    "large_cpu_matrix = torch.rand((dim, dim)) \n",
    "large_gpu_matrix = large_cpu_matrix.to(\"cuda\") # Can also specify \"cuda:gpu_id\" if multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "print(\"Norm of large cpu matrix. Time:\", timeit.timeit(\"large_cpu_matrix.norm()\", number=100))\n",
    "print(\"Norm of large gpu matrix. Time:\", timeit.timeit(\"large_gpu_matrix.norm()\", number=100))"
   ]
  },
  {
   "source": [
    "### Building easy ML models\n",
    "\n",
    "By using all the pieces we've seen till now, we can build our first ML model using PyTorch: a linear regressor, whose model is\n",
    "\n",
    "`y = XW + b`\n",
    "\n",
    "which can also be simplified as\n",
    "\n",
    "`y = WX`\n",
    "\n",
    "if we incorporate the bias `b` inside `W` and add to the `X` a column of ones to the right.\n",
    "\n",
    "We'll first create our data. The `X`s are the 0:9 range plus some iid random noise, while the `y` is just the 0:9 range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X (covariates)\ntensor([[-0.3980,  0.4474,  0.0880,  1.0000],\n        [ 1.3175,  0.7359,  1.0254,  1.0000],\n        [ 2.0527,  1.9036,  2.3399,  1.0000],\n        [ 3.2188,  2.8344,  3.2916,  1.0000],\n        [ 3.8679,  3.5992,  4.1222,  1.0000],\n        [ 4.7422,  4.9182,  5.1700,  1.0000],\n        [ 6.3366,  5.4926,  5.6885,  1.0000],\n        [ 7.8268,  7.5586,  7.1413,  1.0000],\n        [ 7.9029,  8.0806,  7.9835,  1.0000],\n        [ 8.8189,  8.8826,  8.9700,  1.0000]])\n\n\ny (response)\ntensor([[0.],\n        [1.],\n        [2.],\n        [3.],\n        [4.],\n        [5.],\n        [6.],\n        [7.],\n        [8.],\n        [9.]])\n\n\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.range(0, 9).unsqueeze(-1)\n",
    "x2 = torch.range(0, 9).unsqueeze(-1)\n",
    "x3 = torch.range(0, 9).unsqueeze(-1)\n",
    "x0 = torch.ones([10]).unsqueeze(-1)\n",
    "X = torch.cat((x1, x2, x3), dim=1)\n",
    "eps = torch.normal(0, .3, (10, 3))\n",
    "X += eps\n",
    "X = torch.cat((X, x0), dim=1)\n",
    "\n",
    "y = torch.range(0, 9).unsqueeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pretty_print(X, \"X (covariates)\")\n",
    "pretty_print(y, \"y (response)\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "For the case of linear regression, we usually wish to obtain a set of weights minimizing the so called mean square error/loss (MSE), which is the squared difference between the ground truth and the model prediction, summed for each data instance.\n",
    "\n",
    "We know that the OLS/Max Likelihood esitmator is the one yielding the optimal set of weights in that regard."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "W (weights - coefficients and bias/intercept)\ntensor([[ 0.1821],\n        [ 0.0542],\n        [ 0.7771],\n        [-0.1334]])\n\n\n"
     ]
    }
   ],
   "source": [
    "W_hat = ((X.T @ X).inverse()) @ X.T @ y # OLS estimator\n",
    "\n",
    "pretty_print(W_hat, \"W (weights - coefficients and bias/intercept)\")"
   ]
  },
  {
   "source": [
    "We can evaluate our model on the mean square loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_loss(y, y_hat):\n",
    "    return (((y - y_hat).norm())**2).item()"
   ]
  },
  {
   "source": [
    "Let's apply it to our data.\n",
    "\n",
    "First we need to obtain the predictions, then we can evaluate the MSE."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions (y_hat)\ntensor([[-0.1133],\n        [ 0.9432],\n        [ 2.1618],\n        [ 3.1641],\n        [ 3.9692],\n        [ 5.0140],\n        [ 5.7385],\n        [ 7.2507],\n        [ 7.9473],\n        [ 8.9241]])\n\n\nLoss (MSE)\n0.2101009488105774\n\n\n"
     ]
    }
   ],
   "source": [
    "y_hat = X @ W_hat\n",
    "pretty_print(y_hat, \"Predictions (y_hat)\")\n",
    "\n",
    "pretty_print(mean_square_loss(y, y_hat), \"Loss (MSE)\")"
   ]
  },
  {
   "source": [
    "#### Using PT built-ins\n",
    "\n",
    "We can create the same model using PT built-in structures, so we start to see them right away.\n",
    "\n",
    "Usually, a PT model is a `class` inheriting from `torch.nn.Module`. Inside this class, we'll define two methods:\n",
    "* the constructor (`__init__`) in which we define the building blocks of our model as class variables (later during our lectures we'll see more \"elegant\" methods to build models architectures)\n",
    "* the `forward` method, which specifies as the data fed into the model needs to be processed in order to produce the output\n",
    "\n",
    "Note for those who already know something about NNs: we don't need to define `backward` methods since we're constructing our model with built-in PT building blocks. PT automatically creates a `backward` routine based upon the `forward` method.\n",
    "\n",
    "Our model only has one building block (layer) which is a `Linear` layer.\n",
    "We need to specify the size of the input (i.e. the coefficients `W` of our linear regressor) and the size of the output (i.e. how many scalars it produces) of the layer. We additionaly request our layer to has a bias term `b` (which acts as the intercept of the line we saw before).\n",
    "\n",
    "The `Linear` layer processes its input as `XW + b`, which is exactly the (first) equation of the linear regressor we saw before.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.regressor = torch.nn.Linear(in_features=3, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.regressor(X)"
   ]
  },
  {
   "source": [
    "We can create an instance of our model and inspect the current parameters by using the `state_dict` method, which prints the building blocks of our model and their current parameters. Note that `state_dict` is essentially a dictonary indexed by the names of the building blocks which we defined inside the constructor (plus some additional identifiers if a layer has more than one set of parameters)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "regressor.weight tensor([[-0.4430, -0.2483, -0.0019]])\nregressor.bias tensor([-0.1345])\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegressor()\n",
    "\n",
    "for param_name, param in lin_reg.state_dict().items():\n",
    "    print(param_name, param)"
   ]
  },
  {
   "source": [
    "We can update the parameters via `state_dict` and re-using the same OLS estimates we obtained before.\n",
    "\n",
    "Note that PT is thought of for Deep Learning: it does not have (I think) the routines to solve different ML problems.\n",
    "\n",
    "Next time, we'll see as we can unleash PT's gradient-based iterative training routines and compare the results w.r.t. the OLS estimators."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "state_dict = lin_reg.state_dict()\n",
    "state_dict[\"regressor.weight\"] = W_hat[:3].T\n",
    "state_dict[\"regressor.bias\"] = W_hat[3]\n",
    "lin_reg.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "regressor.weight tensor([[0.1821, 0.0542, 0.7771]])\nregressor.bias tensor([-0.1334])\n"
     ]
    }
   ],
   "source": [
    "# Check if it worked\n",
    "for param_name, param in lin_reg.state_dict().items():\n",
    "    print(param_name, param)"
   ]
  },
  {
   "source": [
    "The `forward` method gets implicitly called by passing the data to our model's instance `lin_reg`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions of torch class\ntensor([[-0.1133],\n        [ 0.9432],\n        [ 2.1618],\n        [ 3.1641],\n        [ 3.9692],\n        [ 5.0140],\n        [ 5.7385],\n        [ 7.2507],\n        [ 7.9473],\n        [ 8.9241]], grad_fn=<AddmmBackward>)\n\n\n"
     ]
    }
   ],
   "source": [
    "X_lin_reg = X[:,:3]\n",
    "predictions_lin_reg = lin_reg(X_lin_reg)\n",
    "pretty_print(predictions_lin_reg, \"Predictions of torch class\")"
   ]
  },
  {
   "source": [
    "The predictions are the same as before"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions of linear model\ntensor([[-0.1133],\n        [ 0.9432],\n        [ 2.1618],\n        [ 3.1641],\n        [ 3.9692],\n        [ 5.0140],\n        [ 5.7385],\n        [ 7.2507],\n        [ 7.9473],\n        [ 8.9241]])\n\n\n"
     ]
    }
   ],
   "source": [
    "pretty_print(y_hat, \"Predictions of linear model\")"
   ]
  },
  {
   "source": [
    "### Adding non-linearity\n",
    "\n",
    "One of the staples of DL is that the relationship between the `X`s and the predictions is **non-linear**.\n",
    "\n",
    "The non-linearity is obtain by applying a non-linear function (called *activation function*) after each linear layer.\n",
    "\n",
    "We can complicate just a little bit our linear model to create a **logistic regressor**:\n",
    "\n",
    "`y = logistic(XW + b)`,\n",
    "\n",
    "where `logistic(z) = exp(z) / (1 + exp(z))`\n",
    "\n",
    "The logistic function has different names:\n",
    "* in statistics, it's usually called *inverse logit* as well\n",
    "* in DL and mathematics, it's called *sigmoid function* due to its \"S\" shape\n",
    "\n",
    "Hystorically, the sigmoid was between the first activation functions used in NNs.\n",
    "\n",
    "![](img/sigmoid.png)\n",
    "\n",
    "Logistic regression is usually used as a **binary classification model** instead of a regression model.\n",
    "In this setting, we suppose we have two destination classes to which we assign values 0 and 1: `y ∈ {0, 1}`.\n",
    "Since the codomain of the sigmoid is `[0,1]`, we can interpret its output `ŷ` as a probability value, and assign each data to the class 0 if `ŷ <= 0.5`, to the class 1 otherwise.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y for our classification problem\ntensor([0., 1., 0., 0., 1., 1., 1., 0., 1., 1.])\n\n\n"
     ]
    }
   ],
   "source": [
    "y = torch.Tensor([0,1,0,0,1,1,1,0,1,1])\n",
    "pretty_print(y, \"y for our classification problem\")"
   ]
  },
  {
   "source": [
    "Note that we may also want our y to be a vector of `int`s.\n",
    "We can convert the `Tensor` type to `int` by calling the method `.long()` or `.int()` of `Tensor`.\n",
    "\n",
    "As in NumPy, the type of the `Tensor` is found within the `dtype` variable of the given `Tensor`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y converted to int\ntensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)\n\n\nData type of y\ntorch.int32\n\n\n"
     ]
    }
   ],
   "source": [
    "y = y.int()\n",
    "pretty_print(y, \"y converted to int\")\n",
    "pretty_print(y.dtype, \"Data type of y\")"
   ]
  },
  {
   "source": [
    "Let us now build our logistic regressor in PT.\n",
    "\n",
    "We only need one single addition wrt the linear regressor: in the `forward` method, we'll add the sigmoidal non-linearity by calling the `sigmoid` function within the `torch.nn.functional` library.\n",
    "\n",
    "Note that there also exist some \"mirror\" alias of these functionals within `torch.nn` (e.g. `torch.nn.Sigmoid`): we'll learn in the following lecture why these aliases are there and how to use them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # no difference wrt linear regressor\n",
    "        self.regressor = torch.nn.Linear(in_features=3, out_features=1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self.regressor(X)\n",
    "        # here we apply the sigmoid fct to the output of regressor\n",
    "        out = torch.nn.functional.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "We can instantiate our logistic regressor and use it to calculate our predictions on the same X as before.\n",
    "\n",
    "Note that **we're using the initial (random) weights which PT has assigned to the model parameters**.\n",
    "For our linear regressor, we were able to analytically obtain the OLS value of the parameters.\n",
    "In the case of logistic regression, there's no MaxLikelihood estimator obtainable in close form and we need to resort to numerical methods to obtain them.\n",
    "Since the part concerning numerical optimization will be discussed during the next Lab, we will not be training our model (hence results will obviously be sub-par)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "logistic regressor predictions\ntensor([[0.6664],\n        [0.4910],\n        [0.4088],\n        [0.2862],\n        [0.2292],\n        [0.1603],\n        [0.0828],\n        [0.0401],\n        [0.0399],\n        [0.0268]], grad_fn=<SigmoidBackward>)\n\n\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegressor()\n",
    "y_hat = log_reg(X_lin_reg)\n",
    "pretty_print(y_hat, \"logistic regressor predictions\")"
   ]
  },
  {
   "source": [
    "There exist many ways to evaluate the performance of the logistic regressor: one of them is **accuracy** (correctly identified units / total number of units).\n",
    "We can define a function to evaluate accuracy and calculate it on our model and data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    # Assign each y_hat to its predicted class\n",
    "    pred_classes = torch.where(y_hat < .5, 0, 1).squeeze().int()\n",
    "    correct = (pred_classes == y).sum()\n",
    "    return (correct / y.shape[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.30000001192092896"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "accuracy(y, y_hat)"
   ]
  },
  {
   "source": [
    "#### Visualizing linear and logistic regression as a computational graph\n",
    "\n",
    "We now need to convert the equation of the linear and the logistic regression:\n",
    "* `y = σ(WX + b)`\n",
    "\n",
    "where `σ` is a generic `ℝ → ℝ` function: sigmoid for logistic regression, identity for linear regression.\n",
    "\n",
    "![](img/log_reg_graph.jpg)\n",
    "\n",
    "We organize the input in *nodes* (on the left part) s.t. each node represents one dimension/covariate.\n",
    "For each data instance, we substitute to each node the corresponding numeric value.\n",
    "The nodes undergo one or more operations, namely, from left to right:\n",
    "\n",
    "1. Each node is multiplied by its corresponding weight (a value placed on the edge indicates that the node is multiplied by said value)\n",
    "2. All the corresponding outputs are summed together\n",
    "\n",
    "These two operations identify the dot product between vectors `X` and `W`\n",
    "\n",
    "3. The non-linear function `σ` is applied to the result of this sum\n",
    "4. Finally, we assign that value to the variable `ŷ`, which is also indicated as a node\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Our first MultiLayer Perceptron (MLP)\n",
    "\n",
    "The MLP is a family of Artificial NNs in which the input is a vector of size `ℝ^d` and the output is again a vector of size `ℝ^p`, where `p` is determined upon the nature of the problem we wish to solve. Additionally, a MLP is characterized by multiple stages (*layers*) of sequential vector-matrix multiplication and non-linearity (steps 1., 2., 3. above) in which each output of the layer `l-1` acts as input to the layer `l`.\n",
    "\n",
    "Taking inspiration to the graph of the logistic regression, we can translate all into an image to give sense to these words:\n",
    "\n",
    "![](img/mlp_graph.jpg)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}