{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd02e6347a50883dfa0598d3f478411c8d6a5b9cf8792810af1a6fbd779ad8b1967",
   "display_name": "Python 3.8.8 64-bit ('lot': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2e6347a50883dfa0598d3f478411c8d6a5b9cf8792810af1a6fbd779ad8b1967"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Deep Learning course - LAB 10\n",
    "\n",
    "## Generative Adversarial Networks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Generative Adversarial Networks (GANs) are a neural-based category of generative models.\n",
    "\n",
    "Up to now, we have seen only **discriminating models**, i.e. models tasked with learning $P(Y\\vert X)$, where $X$ are the observations and $Y$ is the dependent variable (category or scalars, depending uon the task).\n",
    "\n",
    "**Generative models**, on the other hand, are tasked with learning $P(Y, X)$, i.e. in simple terms they learn a _**rule**_ through which we can sample (generate) any amount of data.\n",
    "\n",
    "Specifically, GANs are expressed as a game in which two models are in competition:\n",
    "* a **generator** $G$ generates synthetic data\n",
    "* a **discriminator** $D$ distinguishes whether a piece of data is synthetic or not\n",
    "\n",
    "$D$ is usually expressed as a *simple* network for binary classification and trained using the binary cross-entropy loss. Given $D(x)\\in[0,1]$ output of the discriminator and $y\\in\\{0,1\\}$ the ground truth, $\\mathcal{L}_D(x) = -y\\log(D(x)) - (1-y) \\log(1-D(x))$.\n",
    "\n",
    "On the other hand, $G$ is a more complex entity. The input is a *latent variable* $z$, while the output is a point in the data space $\\mathcal{D}$ (i.e. $x\\in\\mathcal{D}$). The generator, recall, is tasked with producing samples which $D$ misclassifies as real. We may then ask for the following: $G^\\star = \\text{argmax}_G \\{ \\mathcal{L}_D(G(z)) \\}$, or, that the generated data $G(z)$ *increase* the loss of $D$. Actually, to \n",
    "\n",
    "Merging the two concepts, we express the GAN in terms of a *minmax* game:\n",
    "\n",
    "$\\min_G \\max_D \\log(D(x)) + \\log(1-D(x))$ (note: the signs are switched w.r.t. $\\mathcal{L}_D$, so the $\\min$ becomes $\\max$ and vice-versa).\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from scripts.mnist import get_data\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader, _, _ = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "source": [
    "this is a free reinterpretation of DCGAN [1](https://arxiv.org/abs/1511.06434) build s.t. we can match the original shape of MNIST. We need to tweak the values of the transposed convolution because the original implementation is thought for images with $n^2$ spatial dimensions, while MNIST does not abide to that prerequisite."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 512, 5, 5])\ntorch.Size([1, 256, 9, 9])\ntorch.Size([1, 128, 21, 21])\ntorch.Size([1, 64, 25, 25])\ntorch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((1,100,1,1))\n",
    "base_width = 64\n",
    "a = nn.ConvTranspose2d(dim_latent, base_width*8, kernel_size=5, bias=False)(a)\n",
    "print(a.shape)\n",
    "a = nn.ConvTranspose2d(base_width*8, base_width*4, kernel_size=5, bias=False)(a)\n",
    "print(a.shape)\n",
    "a = nn.ConvTranspose2d(base_width*4, base_width*2, kernel_size=5, stride=2, bias=False)(a)\n",
    "print(a.shape)\n",
    "a = nn.ConvTranspose2d(base_width*2, base_width*1, kernel_size=5, bias=False)(a)\n",
    "print(a.shape)\n",
    "a = nn.ConvTranspose2d(base_width, 1, kernel_size=4, bias=False)(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, dim_latent, base_width=64, output_ch=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ConvTranspose2d(dim_latent, base_width*8, kernel_size=5, bias=False),\n",
    "            nn.BatchNorm2d(base_width*8),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(base_width*8, base_width*4, kernel_size=5, bias=False),\n",
    "            nn.BatchNorm2d(base_width*4),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(base_width*4, base_width*2, kernel_size=5, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(base_width*2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(base_width*2, base_width, kernel_size=5, bias=False),\n",
    "            nn.BatchNorm2d(base_width),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(base_width, output_ch, kernel_size=4, bias=False),\n",
    "            nn.Tanh() #tanh so the output is in 0-1\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        z = z.unsqueeze(-1).unsqueeze(-1) # append two spatial dimensions to make it image-like\n",
    "        return self.layers(z)"
   ]
  },
  {
   "source": [
    "Let's test if the generator produces an output of the desired shape:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "dim_latent = 100\n",
    "g = Generator(dim_latent=dim_latent)\n",
    "g.apply(weights_init)\n",
    "g(torch.rand((1,dim_latent))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, base_width=64, input_ch=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(input_ch, base_width, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(base_width, base_width*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(base_width*2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(base_width*2, base_width*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(base_width*4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(base_width*4, 1),\n",
    "            nn.Sigmoid() # squeeze output in the 0-1 axis so we can apply the loss\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.layers(X).flatten()"
   ]
  },
  {
   "source": [
    "Check if shape is correct: given batch of size $B$, we expect to have a tensor of shape `[B]` as output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "d = Discriminator()\n",
    "d.apply(weights_init)\n",
    "d(torch.rand(10,1,28,28)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss() # binary cross entropy\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "\n",
    "\n",
    "# for the discriminator\n",
    "sigma_noise = .5\n",
    "\n",
    "lr = 2e-4\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "# 2 Adams with same hyperparameters\n",
    "optim_d = torch.optim.Adam(d.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optim_g = torch.optim.Adam(g.parameters(), lr=lr, betas=(beta1, beta2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite_print = 25\n",
    "num_epochs = 3\n",
    "\n",
    "d = d.to(device)\n",
    "g = g.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fake = 24\n",
    "fixed_noise = torch.randn([n_fake, dim_latent]).to(device)\n",
    "fakeimgs = np.empty([num_epochs, n_fake, 28, 28])\n",
    "\n",
    "def tensor_to_numpy(imgs):\n",
    "    return ((imgs * 0.3081 + 0.1307) * 255).permute(0,2,3,1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ep. 1 It. 25/235 >>> D loss 1.287 | G loss 0.792 >>> D(x) [real] 0.525 | D(G(z)) [fake] 0.473 | D*(G(z)) [fake after D train] 0.453\n",
      "Ep. 1 It. 50/235 >>> D loss 1.226 | G loss 0.847 >>> D(x) [real] 0.546 | D(G(z)) [fake] 0.462 | D*(G(z)) [fake after D train] 0.429\n",
      "Ep. 1 It. 75/235 >>> D loss 1.132 | G loss 0.885 >>> D(x) [real] 0.576 | D(G(z)) [fake] 0.439 | D*(G(z)) [fake after D train] 0.414\n",
      "Ep. 1 It. 100/235 >>> D loss 1.058 | G loss 0.994 >>> D(x) [real] 0.605 | D(G(z)) [fake] 0.424 | D*(G(z)) [fake after D train] 0.371\n",
      "Ep. 1 It. 125/235 >>> D loss 1.017 | G loss 1.098 >>> D(x) [real] 0.606 | D(G(z)) [fake] 0.401 | D*(G(z)) [fake after D train] 0.336\n",
      "Ep. 1 It. 150/235 >>> D loss 0.867 | G loss 1.183 >>> D(x) [real] 0.624 | D(G(z)) [fake] 0.324 | D*(G(z)) [fake after D train] 0.308\n",
      "Ep. 1 It. 175/235 >>> D loss 0.801 | G loss 1.161 >>> D(x) [real] 0.675 | D(G(z)) [fake] 0.332 | D*(G(z)) [fake after D train] 0.316\n",
      "Ep. 1 It. 200/235 >>> D loss 0.754 | G loss 1.214 >>> D(x) [real] 0.712 | D(G(z)) [fake] 0.337 | D*(G(z)) [fake after D train] 0.299\n",
      "Ep. 1 It. 225/235 >>> D loss 0.665 | G loss 1.400 >>> D(x) [real] 0.694 | D(G(z)) [fake] 0.256 | D*(G(z)) [fake after D train] 0.248\n",
      "Ep. 1 It. 235/235 >>> D loss 0.610 | G loss 1.374 >>> D(x) [real] 0.745 | D(G(z)) [fake] 0.269 | D*(G(z)) [fake after D train] 0.255\n",
      "Ep. 2 It. 25/235 >>> D loss 0.656 | G loss 1.400 >>> D(x) [real] 0.709 | D(G(z)) [fake] 0.263 | D*(G(z)) [fake after D train] 0.251\n",
      "Ep. 2 It. 50/235 >>> D loss 0.482 | G loss 1.599 >>> D(x) [real] 0.802 | D(G(z)) [fake] 0.228 | D*(G(z)) [fake after D train] 0.204\n",
      "Ep. 2 It. 75/235 >>> D loss 0.508 | G loss 1.741 >>> D(x) [real] 0.748 | D(G(z)) [fake] 0.194 | D*(G(z)) [fake after D train] 0.178\n",
      "Ep. 2 It. 100/235 >>> D loss 0.542 | G loss 1.817 >>> D(x) [real] 0.804 | D(G(z)) [fake] 0.275 | D*(G(z)) [fake after D train] 0.165\n",
      "Ep. 2 It. 125/235 >>> D loss 0.654 | G loss 1.428 >>> D(x) [real] 0.671 | D(G(z)) [fake] 0.220 | D*(G(z)) [fake after D train] 0.247\n",
      "Ep. 2 It. 150/235 >>> D loss 0.923 | G loss 1.533 >>> D(x) [real] 0.652 | D(G(z)) [fake] 0.387 | D*(G(z)) [fake after D train] 0.221\n",
      "Ep. 2 It. 175/235 >>> D loss 0.796 | G loss 1.829 >>> D(x) [real] 0.820 | D(G(z)) [fake] 0.444 | D*(G(z)) [fake after D train] 0.164\n",
      "Ep. 2 It. 200/235 >>> D loss 0.771 | G loss 1.198 >>> D(x) [real] 0.602 | D(G(z)) [fake] 0.227 | D*(G(z)) [fake after D train] 0.306\n",
      "Ep. 2 It. 225/235 >>> D loss 0.391 | G loss 1.889 >>> D(x) [real] 0.831 | D(G(z)) [fake] 0.184 | D*(G(z)) [fake after D train] 0.155\n",
      "Ep. 2 It. 235/235 >>> D loss 0.428 | G loss 1.905 >>> D(x) [real] 0.834 | D(G(z)) [fake] 0.216 | D*(G(z)) [fake after D train] 0.152\n",
      "Ep. 3 It. 25/235 >>> D loss 0.320 | G loss 1.850 >>> D(x) [real] 0.880 | D(G(z)) [fake] 0.174 | D*(G(z)) [fake after D train] 0.161\n",
      "Ep. 3 It. 50/235 >>> D loss 0.241 | G loss 2.225 >>> D(x) [real] 0.889 | D(G(z)) [fake] 0.116 | D*(G(z)) [fake after D train] 0.110\n",
      "Ep. 3 It. 75/235 >>> D loss 0.231 | G loss 2.313 >>> D(x) [real] 0.891 | D(G(z)) [fake] 0.109 | D*(G(z)) [fake after D train] 0.101\n",
      "Ep. 3 It. 100/235 >>> D loss 0.209 | G loss 2.438 >>> D(x) [real] 0.897 | D(G(z)) [fake] 0.095 | D*(G(z)) [fake after D train] 0.089\n",
      "Ep. 3 It. 125/235 >>> D loss 0.197 | G loss 2.462 >>> D(x) [real] 0.904 | D(G(z)) [fake] 0.092 | D*(G(z)) [fake after D train] 0.087\n",
      "Ep. 3 It. 150/235 >>> D loss 0.194 | G loss 2.528 >>> D(x) [real] 0.906 | D(G(z)) [fake] 0.091 | D*(G(z)) [fake after D train] 0.081\n",
      "Ep. 3 It. 175/235 >>> D loss 0.179 | G loss 2.651 >>> D(x) [real] 0.911 | D(G(z)) [fake] 0.082 | D*(G(z)) [fake after D train] 0.072\n",
      "Ep. 3 It. 200/235 >>> D loss 0.163 | G loss 2.711 >>> D(x) [real] 0.920 | D(G(z)) [fake] 0.076 | D*(G(z)) [fake after D train] 0.068\n",
      "Ep. 3 It. 225/235 >>> D loss 0.159 | G loss 2.775 >>> D(x) [real] 0.918 | D(G(z)) [fake] 0.070 | D*(G(z)) [fake after D train] 0.064\n",
      "Ep. 3 It. 235/235 >>> D loss 0.148 | G loss 2.849 >>> D(x) [real] 0.925 | D(G(z)) [fake] 0.067 | D*(G(z)) [fake after D train] 0.059\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (real_data, _) in enumerate(trainloader):\n",
    "        real_data = real_data.to(device)\n",
    "\n",
    "        # 1 >>>>>> train D\n",
    "        optim_d.zero_grad()\n",
    "\n",
    "        batch_size = real_data.shape[0]\n",
    "\n",
    "        # --- real data part ---\n",
    "        # labels are 1 (real_label) for all elements in the minibatch\n",
    "        gr_truth = torch.full([batch_size], real_label, dtype=torch.float).to(device)\n",
    "        # get prediction for real data\n",
    "        # noisy_real_data = real_data + torch.normal(0, sigma_noise, real_data.shape, device=device)\n",
    "        pred_d_real = d(real_data).view(-1)\n",
    "        err_d_real = loss_fn(pred_d_real, gr_truth)\n",
    "        err_d_real.backward()\n",
    "        # this will be used only in the summary\n",
    "        mean_prediction_d_real = pred_d_real.mean().item()\n",
    "\n",
    "        # --- fake data part ---\n",
    "        # generate gaussian noise\n",
    "        noise = torch.randn([batch_size, dim_latent]).to(device)\n",
    "        # generate fake images\n",
    "        synthetic_dat = g(noise)\n",
    "        # labels are 0 (fake_label) for all elements in the minibatch\n",
    "        gr_truth.fill_(fake_label)\n",
    "        # get prediction for fake data\n",
    "        pred_d_fake = d(synthetic_dat.detach()).view(-1) # Note: don't want to backpropagate errors through the generator for now!\n",
    "        err_d_fake = loss_fn(pred_d_fake, gr_truth)\n",
    "        err_d_fake.backward()\n",
    "        # these two serve only for summary purposes\n",
    "        mean_prediction_d_fake = pred_d_fake.mean().item()\n",
    "        err_d_overall = err_d_fake + err_d_real\n",
    "\n",
    "        optim_d.step()\n",
    "\n",
    "        # 2 >>>>>> train G\n",
    "        optim_g.zero_grad()\n",
    "        # invert the fake/real label -- now they're all real!\n",
    "        gr_truth.fill_(real_label)\n",
    "        # re-feed the synthetic data to the newly-trained discriminator\n",
    "        pred_d_g = d(synthetic_dat).view(-1)\n",
    "        # this time, get error on G's side\n",
    "        err_g = loss_fn(pred_d_g, gr_truth)\n",
    "        err_g.backward()\n",
    "        mean_prediction_d_g = pred_d_g.mean().item()\n",
    "        optim_g.step()\n",
    "\n",
    "        if (i + 1) % ite_print == 0 or (i + 1) == len(trainloader):\n",
    "            print(f\"Ep. {epoch + 1} It. {i+1}/{len(trainloader)} >>> D loss {err_d_overall.item():.3f} | G loss {err_g.item():.3f} >>> D(x) [real] {mean_prediction_d_real:.3f} | D(G(z)) [fake] {mean_prediction_d_fake:.3f} | D*(G(z)) [fake after D train] {mean_prediction_d_g:.3f}\")\n",
    "    \n",
    "    # after each epoch, do some generation...\n",
    "    sample = g(fixed_noise).detach().cpu()\n",
    "    fakeimgs[epoch] = tensor_to_numpy(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1144288d00>"
      ]
     },
     "metadata": {},
     "execution_count": 173
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-07T18:01:18.313101</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p418a25807d)\">\n    <image height=\"218\" id=\"imagea656c0d603\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m21fe39f285\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m21fe39f285\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m21fe39f285\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m21fe39f285\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m21fe39f285\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m21fe39f285\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m21fe39f285\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mf10f75971b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf10f75971b\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf10f75971b\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf10f75971b\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf10f75971b\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf10f75971b\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf10f75971b\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p418a25807d\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(fakeimgs[2,0], cmap=\"gray\")"
   ]
  },
  {
   "source": [
    "## Wasserstein GAN\n",
    "\n",
    "The Wasserstein GAN (WGAN) ([2](https://arxiv.org/pdf/1701.07875.pdf)) replaces the discriminator with a **critic**, which is still an ANN, but with a different loss function: while the discriminator minimizes the binary cross-entropy loss, the critic minimizes an approximation of the **Wasserstein Distance** (also called Earth Mover's Distance, EMD) between the real distribution of data ($P_r$) and the *guide* distribution ($P_\\theta$), which is the distribution being learned by our generator.\n",
    "\n",
    "![](img/emd.jpg)\n",
    "\n",
    "$EMD(P_r, P_\\theta) = \\inf_{\\gamma\\in\\Pi(P_r,P_\\theta)} \\text{E}_{(x,y)\\sim\\gamma}(\\vert\\vert x-y \\vert\\vert)$\n",
    "\n",
    "Here, $\\Pi(P_r,P_\\theta)$ represent the family of all possible joint distribution of $X, Y$ whose marginal $P(X)=P_r$ and $P(Y)=P_\\theta$, and $\\gamma$ is hence a sample from this family.\n",
    "\n",
    "More specifically, we wish to find the *minimal density mass* to be transported from $P_\\theta$ to $P_r$ such that $P_\\theta$ *becomes* $P_r$.\n",
    "\n",
    "It turns out that the critic can be an ANN $f_w$ trained by back-propagating the gradient according to the following loss function:\n",
    "\n",
    "$\\mathcal{L}_f = \\frac{1}{b}\\sum_{i=1}^{b} f_w(x^{(i)}) - \\frac{1}{b}\\sum_{i=1}^{b}f_w(g_\\theta(z^{(i)}))$\n",
    "\n",
    "The notation is easily inferrable from before:\n",
    "* $b$ is the batch size\n",
    "* $g$ is the generator parametrized by $\\theta$\n",
    "* $z$ is a sample from the *guide distribution* (usually, a Gaussian)\n",
    "\n",
    "$w$ (parameters of $f$) is then updated using RMSProp (in the original paper) and clipping the resulting new parameters in the interval $[-0.01, 0.01]$.\n",
    "\n",
    "The loss of $g$ is instead\n",
    "\n",
    "$\\mathcal{L}_g = \\frac{1}{b}\\sum_{i=1}^{m}f_w(g_\\theta(z^{(i)}))$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator().to(device)\n",
    "g = Generator(100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_critic = lambda pred_critic : pred_critic.mean()\n",
    "loss_fn_gener = lambda pred_critic_generated : -pred_critic_generated.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_d = torch.optim.RMSprop(d.parameters(), lr=5e-5)\n",
    "optim_g = torch.optim.RMSprop(g.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the ratio of critic update vs generator update\n",
    "n_critic_training = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ep. 1 It. 25/235 >>> Critic loss -0.205 | G loss -0.661\n",
      "Ep. 1 It. 50/235 >>> Critic loss -0.276 | G loss -0.741\n",
      "Ep. 1 It. 75/235 >>> Critic loss -0.302 | G loss -0.782\n",
      "Ep. 1 It. 100/235 >>> Critic loss -0.327 | G loss -0.809\n",
      "Ep. 1 It. 125/235 >>> Critic loss -0.338 | G loss -0.830\n",
      "Ep. 1 It. 150/235 >>> Critic loss -0.346 | G loss -0.847\n",
      "Ep. 1 It. 175/235 >>> Critic loss -0.354 | G loss -0.861\n",
      "Ep. 1 It. 200/235 >>> Critic loss -0.360 | G loss -0.874\n",
      "Ep. 1 It. 225/235 >>> Critic loss -0.358 | G loss -0.884\n",
      "Ep. 1 It. 235/235 >>> Critic loss -0.361 | G loss -0.888\n",
      "Ep. 2 It. 25/235 >>> Critic loss -0.359 | G loss -0.897\n",
      "Ep. 2 It. 50/235 >>> Critic loss -0.363 | G loss -0.904\n",
      "Ep. 2 It. 75/235 >>> Critic loss -0.370 | G loss -0.911\n",
      "Ep. 2 It. 100/235 >>> Critic loss -0.383 | G loss -0.917\n",
      "Ep. 2 It. 125/235 >>> Critic loss -0.387 | G loss -0.923\n",
      "Ep. 2 It. 150/235 >>> Critic loss -0.387 | G loss -0.928\n",
      "Ep. 2 It. 175/235 >>> Critic loss -0.402 | G loss -0.933\n",
      "Ep. 2 It. 200/235 >>> Critic loss -0.427 | G loss -0.937\n",
      "Ep. 2 It. 225/235 >>> Critic loss -0.465 | G loss -0.942\n",
      "Ep. 2 It. 235/235 >>> Critic loss -0.446 | G loss -0.943\n",
      "Ep. 3 It. 25/235 >>> Critic loss -0.477 | G loss -0.947\n",
      "Ep. 3 It. 50/235 >>> Critic loss -0.533 | G loss -0.951\n",
      "Ep. 3 It. 75/235 >>> Critic loss -0.498 | G loss -0.955\n",
      "Ep. 3 It. 100/235 >>> Critic loss -0.491 | G loss -0.958\n",
      "Ep. 3 It. 125/235 >>> Critic loss -0.527 | G loss -0.961\n",
      "Ep. 3 It. 150/235 >>> Critic loss -0.573 | G loss -0.964\n",
      "Ep. 3 It. 175/235 >>> Critic loss -0.555 | G loss -0.966\n",
      "Ep. 3 It. 200/235 >>> Critic loss -0.533 | G loss -0.968\n",
      "Ep. 3 It. 225/235 >>> Critic loss -0.559 | G loss -0.970\n",
      "Ep. 3 It. 235/235 >>> Critic loss -0.558 | G loss -0.970\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (real_data, _) in enumerate(trainloader):\n",
    "        real_data = real_data.to(device)\n",
    "\n",
    "        # 1 >>>>>> train D\n",
    "        optim_d.zero_grad()\n",
    "\n",
    "        batch_size = real_data.shape[0]\n",
    "\n",
    "        # --- real data part ---\n",
    "        # labels are 1 (real_label) for all elements in the minibatch\n",
    "        # gr_truth = torch.full([batch_size], real_label, dtype=torch.float).to(device)\n",
    "\n",
    "        # get prediction for real data\n",
    "        # noisy_real_data = real_data + torch.normal(0, sigma_noise, real_data.shape, device=device)\n",
    "        pred_d_real = d(real_data).view(-1)\n",
    "        err_d_real = loss_fn_critic(pred_d_real)\n",
    "        err_d_real.backward()\n",
    "        # this will be used only in the summary\n",
    "        # mean_prediction_d_real = pred_d_real.mean().item()\n",
    "\n",
    "        # --- fake data part ---\n",
    "        # generate gaussian noise\n",
    "        noise = torch.randn([batch_size, dim_latent]).to(device)\n",
    "        # generate fake images\n",
    "        synthetic_data = g(noise)\n",
    "        # labels are 0 (fake_label) for all elements in the minibatch\n",
    "        #gr_truth.fill_(fake_label)\n",
    "        # get prediction for fake data\n",
    "        pred_d_fake = d(synthetic_data.detach()).view(-1)\n",
    "        err_d_fake = loss_fn_gener(pred_d_fake)\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_value_(d.parameters(), 0.01)\n",
    "        err_d_fake.backward()\n",
    "        # these two serve only for summary purposes\n",
    "        # mean_prediction_d_fake = pred_d_fake.mean().item()\n",
    "        err_d_overall = err_d_fake + err_d_real\n",
    "\n",
    "        optim_d.step()\n",
    "\n",
    "        # 2 >>>>>> train G\n",
    "        if (i + 1) % n_critic_training == 0:\n",
    "            optim_g.zero_grad()\n",
    "            # invert the fake/real label -- now they're all real!\n",
    "            # gr_truth.fill_(real_label)\n",
    "            # re-feed the synthetic data to the newly-trained discriminator\n",
    "            # generate new noise (required by paper)\n",
    "            noise = torch.randn([batch_size, dim_latent]).to(device)\n",
    "            synthetic_data = g(noise)\n",
    "            pred_d_g = d(synthetic_data).view(-1)\n",
    "            # this time, get error on G's side\n",
    "            err_g = loss_fn_gener(pred_d_g)\n",
    "            err_g.backward()\n",
    "\n",
    "        if (i + 1) % ite_print == 0 or (i + 1) == len(trainloader):\n",
    "            print(f\"Ep. {epoch + 1} It. {i+1}/{len(trainloader)} >>> Critic loss {err_d_overall.item():.3f} | G loss {err_g.item():.3f}\")\n",
    "    \n",
    "    # after each epoch, do some generation...\n",
    "    sample = g(fixed_noise).detach().cpu()\n",
    "    fakeimgs[epoch] = tensor_to_numpy(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1144b54580>"
      ]
     },
     "metadata": {},
     "execution_count": 198
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-07T18:44:48.077935</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p01037cd04b)\">\n    <image height=\"218\" id=\"image299f2343e1\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m33ab6fa9a3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m33ab6fa9a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m33ab6fa9a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m33ab6fa9a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m33ab6fa9a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m33ab6fa9a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m33ab6fa9a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m95d63975e2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m95d63975e2\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m95d63975e2\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m95d63975e2\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m95d63975e2\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m95d63975e2\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m95d63975e2\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p01037cd04b\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYj0lEQVR4nO3dfXDU1bkH8O+jEsCEIIgEBBREoSKtVDMOrXLFUSlQWmEGHbEqUhVbLcVR5krVjrS2Dl5urVavTvEVLMrQ8qIV64UiiGhRUoq8XHwBTSUQiFygEkBewnP/YO1wbc73pLvJbqbn+5lhAvvN2T0sedhkz+88x9wdIvKv75hCT0BE8kPFLpIIFbtIIlTsIolQsYsk4rh8PljLli29uLiY5XT8/v37s8oA4NChQzQ//vjjaV5bWxvMYvOOPXZRUVFO4w8fPhzMjj322KzHAsDBgwdpHps7W+057jj+5WdmNN+7d2/W42PPS+zroa6ujuax57VFixbBLPacs/s+cOAADh48WO9fPKdiN7PBAB4CcCyAJ9x9Mvv84uJiXHrppcG8R48e9PEqKyuD2UcffUTHbtu2jebl5eU0f+ONN4JZ9+7d6djt27fTvFu3bjTfsWMHzfft2xfMSktL6djPPvuM5lVVVTQ/5ZRTaH7gwIFgVlZWRscecwz/xnPVqlU0Z/8Jt23blo49++yzab579+6c8pNPPjmYbd26lY5l/2Zr164NZll/G29mxwL4LwBDAPQBMMrM+mR7fyLStHL5mf08ABvc/UN3PwBgJoDLGmdaItLYcin2LgA2HfXnqsxt/4+ZjTWzCjOriP1cLSJNJ5dir+9NgH94N8bdp7p7ubuXx97IEpGmk0uxVwE4+p2lrgC25DYdEWkquRT7CgBnmFkPMysCcCWAFxtnWiLS2LJeenP3Q2b2AwD/jSNLb0+5+zo2xszocsjKlSvpY/bv3z+YxdZsW7duTfPYmm3Hjh2D2aZNm4IZAFx11VU0r6iooPnGjRtp3r59+2D24Ycf0rEjRoyg+fvvv0/ziRMn0nzMmDHBLLbUGnvsm266iebPP/98MLvooovoWLaEBQBnnHEGzWM/su7atSuYffOb36Rjn3322WDG1uBzWmd395cBvJzLfYhIfuhyWZFEqNhFEqFiF0mEil0kESp2kUSo2EUSkdf97HV1dfj000+DeWybat++fYNZbC163Tp6CUB0fzLbG92zZ086NrbNdOfOnTS/4447aD579uxgtmULv6jx7bffpvnFF19M8xtuuIHm7N9s+fLldGxsL8Vjjz1G8z179gSz6dOn07GxvfRDhw6l+bx582jO/l1uvvlmOrakpCSYsX36emUXSYSKXSQRKnaRRKjYRRKhYhdJhIpdJBF5XXpr3bo1+vQJ96RcsmQJHX/66acHM7btDwBee+01mn/rW9+iOevgetllvPXej3/8Y5pfcsklNL/66qtpPnr06GAW6/46YcIEmsfGL1q0iOasA+zmzZvpWNaBFQAefPBBmt92223B7KWXXqJjY1t3zz33XJovWLCA5mz57JNPPqFjWbdh1nZcr+wiiVCxiyRCxS6SCBW7SCJU7CKJULGLJELFLpKIvK6z19bW4k9/+lMwj20FZWvCse2OsXXRWMtl1vb47rvvpmPvvfdemsdaJse20M6fPz+YxU5CHTduHM2HDRtG83fffZfmp512WjCLzS127HFsLZxtkY21/45tv41dA3DSSSfR/K233gpmGzZsoGNZ23P2nOmVXSQRKnaRRKjYRRKhYhdJhIpdJBEqdpFEqNhFEpHXdfaSkhJ67PJ7771Hx5944onBLLYfPebRRx+lOVunb9euHR3L9uED8Rba7k7zBx54IJix1sINue+nn36a5gMHDqQ5O0p75syZOd33pZdeSvPevXsHswEDBtCx77zzDs3Zcw7E+wSsWLEimF1xxRV0LDuKmrXAzqnYzawSwG4AdQAOuXt5LvcnIk2nMV7ZL3L37Y1wPyLShPQzu0gici12B7DAzP5sZmPr+wQzG2tmFWZWwa7pFZGmleu38ee7+xYz6whgoZm96+5Lj/4Ed58KYCoAdO7cmb8bJCJNJqdXdnffkvlYA2AugPMaY1Ii0viyLnYzKzazNp//HsAgAGsba2Ii0rhy+Ta+DMDczLrecQCec/dX2IC6ujrU1tZm/YCsn/bq1avp2Nh68s9+9jOas37cNTU1dOzgwYNpHjseODb3X//618GsvJyvhrIe5ADw85//nOaxo7DZvu/YNQBDhgyh+Z133knzli1bBrO77rqLjmVr2QDw8ccf03zx4sU079WrVzCL9T9g13WwGsm62N39QwBnZzteRPJLS28iiVCxiyRCxS6SCBW7SCJU7CKJyHsr6WXLlgVzdvQwADzyyCPBjLXmBfj2WCB+xC5bKmEZALRp04bmbFkPiC9Rse29sblVVFTQfN68eTSPzZ21uR4+fDgdW1RURPOxY+u9Qvvv2BbaWPvvsrIymseWU2OtydlSb2ypdcSIEcFMRzaLiIpdJBUqdpFEqNhFEqFiF0mEil0kESp2kUTkdZ29tLSUtv+NtXNmba1uuOEGOnbWrFk079ChA81ZW+IpU6bQsStXrqR5TGydvWPHjsEsto4euwYg1uaatYoG+Jrxiy++SMfG2oN/8MEHNGfHg7N/TyB+TPZzzz1H89jfbeTIkcEs1iKbPedsu7Re2UUSoWIXSYSKXSQRKnaRRKjYRRKhYhdJhIpdJBF5XWevq6vDrl27gnmnTp3o+GOOCf/fFGvdG1vrjh0PzCxdupTmhw8fpnmslXTfvn1pHvu756JHjx40r6ury/q+Y+vor7/+Os1jba6/9KUvBbPYvGP70bdt20bzMWPG0Ly0tDSYXX311XTsyy+/HMzYdQ16ZRdJhIpdJBEqdpFEqNhFEqFiF0mEil0kESp2kUTkdZ3dzOjebHbcLAB63POgQYPo2B/96Ec0v+qqq2h+0UUXBbPY3uXYfceOB161ahXN2drqCSecQMf+7W9/o3llZSXNDx48SPMWLVoEs1h/9Nj1B7HnhZ0FwK7ZAIBx48bRPLaXPnY0+amnnhrMiouL6Vh27cOnn34azKKv7Gb2lJnVmNnao25rb2YLzeyDzMfwgdEi0iw05Nv4ZwB88fiLiQAWufsZABZl/iwizVi02N19KYAdX7j5MgDTMr+fBmB4405LRBpbtm/Qlbl7NQBkPgaboJnZWDOrMLOKffv2ZflwIpKrJn833t2nunu5u5e3bt26qR9ORAKyLfZtZtYZADIfaxpvSiLSFLIt9hcBfH6+8mgALzTOdESkqUTX2c3seQADAXQwsyoA9wCYDGCWmV0P4GMAlzfkwXbv3o0lS5YE80suuYSOnz17djCLnb8e648+Z84cmk+dOjWYxdaDcxXbD896u8fW0WNrujt37qQ5W0ePyfV5mzt3Ls3Z8xabd0lJCc0nT55M89g1BGw/fOx5qaqqCmbsuodosbv7qEB0cWysiDQfulxWJBEqdpFEqNhFEqFiF0mEil0kERZbImhMrVq18m7dugXz2PG/bFvhxo0b6djOnTvTPNa+d9GiRcHsySefpGOHDx9O86KiIprHtpGyZaLYst2ePXtoHlsGin39sC3NsbnFjqqOPS+nnXZaMNu8eXNO9x37ew8YMIDml18eXq2Ote+eMWNGMFuwYAF27NhR7z+aXtlFEqFiF0mEil0kESp2kUSo2EUSoWIXSYSKXSQReW0l3apVK5x11lnBPLYNtaYm3CMjtsW1ZcuWNI9tr73nnnuC2YgRI+jY2JHLsTXdmDVr1gSz2JptbB39uuuuo/nIkSNpzp732DbTWBvsWDtodk1H27Zt6djt27fTfPz48TQvLy+n+YQJE4IZ+/cEgIULFwaznFpJi8i/BhW7SCJU7CKJULGLJELFLpIIFbtIIlTsIonI6zp7ixYt0KlTp2D++9//no5na4ix457nz59P8+nTp9OcHfkc29v8/e9/n+axddXYfvcuXbrQnFm8eDHNWQttgLf3BoClS5cGsyuvvJKOra6upnlMRUVFMNu9ezcd+73vfY/mX/nKV2geu/5g2LBhwSx2/QHL2XUTemUXSYSKXSQRKnaRRKjYRRKhYhdJhIpdJBEqdpFE5LVvfJcuXZytOZ977rl0/NChQ4NZrMd4LI89D++++24wu+CCC+jY2Hpx7LFje85ZHtt3/eijj9J83rx5NP/GN75B89jzzuT6vPTv3z+YLV++nI7t1asXzdkZBgBw6NAhmrNrJ9j1AQBw4YUXBrPa2lrU1dVl1zfezJ4ysxozW3vUbZPMbLOZrcr8ClehiDQLDfk2/hkAg+u5/Zfu3i/z6+XGnZaINLZosbv7UgA78jAXEWlCubxB9wMzW535Nr9d6JPMbKyZVZhZRexcMRFpOtkW+2MAegLoB6AawC9Cn+juU9293N3Li4uLs3w4EclVVsXu7tvcvc7dDwN4HMB5jTstEWlsWRW7mR19/vEIAGtDnysizUN0P7uZPQ9gIIAOZlYF4B4AA82sHwAHUAngpoY+IDuT+4c//GFD7+Yf/OEPf6D5oEGDaF5WVkbznj17BrNnn32Wjo31Xn/nnXdoHsOe0969e9OxmzZtonnseYkZN25cMLv//vvp2DPPPDOnx37zzTeDWez9o9LSUpqzrwcA2L9/P81ZT/tXX32Vju3Tp08wY70RosXu7qPqufnJ2DgRaV50uaxIIlTsIolQsYskQsUukggVu0gi8tpKeu/evVi9enUwjy3FsNbDkyZNomNjWxLPOy/764J++9vf0ryuro7m/fr1y/qxgfhWT2bKlCk5PXbs2OSHH344q6whDhw4QHM2t3POOYeO7dq1K81btWpFc9b2HAA6dOgQzAYMGEDH3nfffcHss88+C2Z6ZRdJhIpdJBEqdpFEqNhFEqFiF0mEil0kESp2kUTkdZ29rq4OO3aE29nddtttdDxbN50zZw4d27lzZ5rH1my3b98ezNq2bUvH/u53v6N57Mjlu+66i+axtsjMd77zHZqPGTOG5my7JcCPwr722mvp2NgaPtvaCwBt2rQJZjNnzqRj+/btS3PWWhwAJk6cSHPWYnvz5s10LPt62bt3bzDTK7tIIlTsIolQsYskQsUukggVu0giVOwiiVCxiyQir0c2l5aWenl5eTA/+eST6fiXXnopmD3++ON07AknnEDzN954g+Zs73Vsjb62tpbmsf3oN93EO3W/8sorwayyspKOff3112ke21ud67HKuYgdB836CMTmFVsnX7FiBc3vvvtumt9+++3B7JlnnqFjhw0bFsyqq6uxf//+7I5sFpF/DSp2kUSo2EUSoWIXSYSKXSQRKnaRRKjYRRKR1/3sLVq0oHtxY/t4WS/uWJ/vr3/96zT/61//SvOf/OQnwez444+nY6+//nqaP/HEEzTftm0bzadOnUpz5sILL8x6LACsXbuW5uzo49g1AEuWLKH58OHDab5s2bJg1qtXLzo2hvVnB4C//OUvNF+3bl0w++Mf/0jHtmvXLpjV1NQEs+gru5l1M7PFZrbezNaZ2fjM7e3NbKGZfZD5GJ6BiBRcQ76NPwTgdnc/E0B/ALeYWR8AEwEscvczACzK/FlEmqlosbt7tbuvzPx+N4D1ALoAuAzAtMynTQMwvInmKCKN4J96g87MugP4KoC3AJS5ezVw5D8EAB0DY8aaWYWZVezfvz/H6YpIthpc7GZWAmA2gFvdnZ9adxR3n+ru5e5e3rJly2zmKCKNoEHFbmYtcKTQZ7j7521ct5lZ50zeGUD4bUARKbjoFlc7shdwGoAd7n7rUbdPAfC/7j7ZzCYCaO/u/87uq2vXrn7LLbcE87PPPpvOZeTIkcFs1qxZdOy3v/1tmueyVTPXbcKxlsmx+2ctk/fs2UPHxo6Tji0xxY4uPu648Ooua88NxLc8s7bJMbHvMk899VSax/7NBg0aRHPWijq2xbV///7BbOvWrcEtrg1ZZz8fwDUA1pjZqsxtdwKYDGCWmV0P4GMAlzfgvkSkQKLF7u7LAIRe1i5u3OmISFPR5bIiiVCxiyRCxS6SCBW7SCJU7CKJyOsW16KiIvTo0SOY33///XQ8W0+ObY9l670AMGPGDJqzLbCxtsHvv/8+zWNrurEtrOx5q66upmNj23O/+93v0jyXawxiLba3bt1Kc3b8NwCccsopwezQoUN07OWX85XkWPvwXbt20Zy16H7zzTfp2J49ewaznTt3BjO9soskQsUukggVu0giVOwiiVCxiyRCxS6SCBW7SCLyus4OxNc3mbPOOiuYdevWjY699tpraX7ffffRnK2r3nvvvXTs6aefTvPnnnuO5h071tvx6+/Y0cXFxcV0bOz6g9h+9dj1CWxu+/bto2Nfe+01mg8cOJDmrAdB7NqF2GNPmTKF5g8++CDN2To869sAABs2bAhmrP+AXtlFEqFiF0mEil0kESp2kUSo2EUSoWIXSYSKXSQReV1n37VrF1544YVgznppA/zY5S1bttCxRUVFNO/UqRPNx48fH8w++ugjOja2J/zii3mT3tha+HvvvZf1WLbnG4ivs69cuZLm7NqISZMm0bEPP/wwzZcvX07zp59+Ophdc801dOzGjRtpPnjwYJo/9NBDNGfr7LFe/ayvwyeffBLM9MoukggVu0giVOwiiVCxiyRCxS6SCBW7SCJU7CKJiK6zm1k3ANMBdAJwGMBUd3/IzCYBuBHA5wt7d7r7y+y+SkpKaL/sysrKhs26Hq+++irNY2uXNTU1NB82bFgw++lPf0rHPvHEEzT/2te+RvMxY8bQ/Oabbw5msX3+c+bMoXm/fv1oHptb27ZtgxlbgweA+fPn07yqqorm7NoL1l8dAH71q1/RPHb9wejRo2m+YsWKYNahQwc6dsiQIcHsN7/5TTBryEU1hwDc7u4rzawNgD+b2cJM9kt3/88G3IeIFFhDzmevBlCd+f1uM1sPoEtTT0xEGtc/9TO7mXUH8FUAb2Vu+oGZrTazp8ysXWDMWDOrMLOK2HE/ItJ0GlzsZlYCYDaAW939UwCPAegJoB+OvPL/or5x7j7V3cvdvbykpCT3GYtIVhpU7GbWAkcKfYa7zwEAd9/m7nXufhjA4wDOa7ppikiuosVuR1p0Pglgvbs/cNTtnY/6tBEA1jb+9ESksTTk3fjzAVwDYI2ZrcrcdieAUWbWD4ADqARwU+yOzIxuufzyl79Mx7OllNjyVe/evWm+fft2mrNW0rHtkOvXr6d5u3b1vt3xd7feeivNBw0aFMwmTJhAx8aOHo61yb7xxhtpPm3atGBWVlZGxw4dOpTmvXr1yjpnR3ADwKhRo2gea4k+d+5cmrNjut9++206trS0NJix1t0NeTd+GYD6GnDTNXURaV50BZ1IIlTsIolQsYskQsUukggVu0giVOwiichrK2l3x+HDh4N5bN2VbUuMXXfPWlgDQPfu3WnOtsDG2jE/8sgjNI9dX8BaBwP8aGK2/RUA7rjjDpqvXcuvlYpdQ8Cem6VLl9KxixcvpnmsffiaNWuCGdt6C8SvfejZsyfNW7duTfNVq1YFM9YOGuDba9nXgl7ZRRKhYhdJhIpdJBEqdpFEqNhFEqFiF0mEil0kEebu+Xsws08AHL2RuAMAvpG8cJrr3JrrvADNLVuNObdT3f2k+oK8Fvs/PLhZhbuXF2wCRHOdW3OdF6C5ZStfc9O38SKJULGLJKLQxT61wI/PNNe5Ndd5AZpbtvIyt4L+zC4i+VPoV3YRyRMVu0giClLsZjbYzN4zsw1mNrEQcwgxs0ozW2Nmq8ysosBzecrMasxs7VG3tTezhWb2QeYj33id37lNMrPNmedulZnxxu9NN7duZrbYzNab2TozG5+5vaDPHZlXXp63vP/MbmbHAngfwKUAqgCsADDK3f8nrxMJMLNKAOXuXvALMMzs3wDUApju7n0zt/0HgB3uPjnzH2U7d+cdKPI3t0kAagt9jHfmtKLORx8zDmA4gOtQwOeOzOsK5OF5K8Qr+3kANrj7h+5+AMBMAJcVYB7NnrsvBbDjCzdfBuDzY1am4cgXS94F5tYsuHu1u6/M/H43gM+PGS/oc0fmlReFKPYuADYd9ecqNK/z3h3AAjP7s5mNLfRk6lHm7tXAkS8eAB0LPJ8vih7jnU9fOGa82Tx32Rx/nqtCFHt9TbKa0/rf+e5+DoAhAG7JfLsqDdOgY7zzpZ5jxpuFbI8/z1Uhir0KQLej/twVAO8cmEfuviXzsQbAXDS/o6i3fX6CbuZjuBNmnjWnY7zrO2YczeC5K+Tx54Uo9hUAzjCzHmZWBOBKAC8WYB7/wMyKM2+cwMyKAQxC8zuK+kUAozO/Hw2At83No+ZyjHfomHEU+Lkr+PHn7p73XwCG4sg78hsB3FWIOQTmdRqAdzK/1hV6bgCex5Fv6w7iyHdE1wM4EcAiAB9kPrZvRnN7FsAaAKtxpLA6F2huF+DIj4arAazK/Bpa6OeOzCsvz5sulxVJhK6gE0mEil0kESp2kUSo2EUSoWIXSYSKXSQRKnaRRPwfqs86zNV/hh0AAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(fakeimgs[2,10], cmap=\"gray\")"
   ]
  },
  {
   "source": [
    "#### References\n",
    "\n",
    "[1](https://arxiv.org/abs/1511.06434) Radford, Alec, Luke Metz, and Soumith Chintala. \"Unsupervised representation learning with deep convolutional generative adversarial networks.\"\n",
    "\n",
    "[2](https://arxiv.org/pdf/1701.07875.pdf) Arjovsky, Martin, et al. \"Wasserstein GAN.\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}