{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd08aec2e4cca6a43ecda9b11f31ea0f9f4b012d28e6de8cbdf64a5e136ca9a5fb0",
   "display_name": "Python 3.8.6 64-bit ('lottery')"
  },
  "metadata": {
   "interpreter": {
    "hash": "8aec2e4cca6a43ecda9b11f31ea0f9f4b012d28e6de8cbdf64a5e136ca9a5fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Deep Learning course - LAB 7\n",
    "\n",
    "## ConvNets 101"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Recap from previous Lab\n",
    "\n",
    "* we introduced some basic image processing functionalities with OpenCV\n",
    "* we saw how to import a custom dataset in PyTorch, how to operate data augmentation, and how to create a DataLoader out of it\n",
    "\n",
    "### Agenda for today\n",
    "\n",
    "* we will construct our first Convolutional Neural Network (CNN)\n",
    "* we will show how to do transfer learning on CNNs\n",
    "* we will show how to introduce Deconvolution/Inverse Convolution inside CNNs\n",
    "* we will construct our own implementation of two famous CNN architectures: ResNet and U-Net"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Our first CNN\n",
    "\n",
    "Building CNNs is actually not hard once you know all the pieces to construct a MultiLayer Perceptron.\n",
    "\n",
    "We can distinguish between two macro-categories of CNNs, at least for the part concerning image classification. We might call them \"historical\" and \"modern\", although characteristics of both can sometimes get pretty much mixed-up.\n",
    "\n",
    "* \"Historical\" CNNs are a stack composed of two parts:\n",
    "  * a **convolutional** part, where have a cascade of convolutional layers intertwined with pooling layers for dimensionality and complexity reduction\n",
    "    * usually the filters in each convolutional layer are more numerous as the image size shrinks (i.e., as we get further from the input)\n",
    "  * a **fully-connected** part, where we have a sequence of few fully-connected layer, ending up in the output layer, where, as usual, we have as many neurons as there are categories\n",
    "  \n",
    " the epitome of the historical CNN (which is still used in research today nonetheless) is VGGNet (or simply VGG). Its *core* is a **convolutional block** composed of two or three convolutional layers each with the same number of filters, which is double the number of filters of the previous layer, up to 512 filters per layer. At the end of each block, there's a Max Pooling layer which halves the spatial dimension of the image.\n",
    "\n",
    " In the picture below, you can see a modern implementation of VGG with only one fully-connected layer.\n",
    "  ![](img/vgg.png)\n",
    "  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* \"Modern\" CNNs, instead, get rid of the fully-connected part, as usually\n",
    "    1. it introduces a considerable amount of parameters in the network (note that the convolutional layers, due to their local connectivity and shared weights, have a much lower number of parameters w.r.t. fully connected layers)\n",
    "    2. it keeps the 2D spatial structure of the image intact up to the last hidden layer, allowing for more interpretal parameters/neurons (*insert Olah citation here*)\n",
    "    3. it represents a \"rigid\" portion of the network in the sense that it constrains they size of the image to be fixed. We will see later how this can pose a problem.\n",
    "\n",
    " Sometimes, even the pooling layers may get replaced by convolutional layers with large kernel size, as its effect is to reduce dimensionality (i.e., height and width) of the corresponding image.\n",
    " \n",
    " Recently, the **residual block** has become one of the paramount structures in modern CNNs. It forces the network to learn image features by actually learning to *reconstruct itself* (sometimes in lower spatial dimensionality) rather than learn immediately features for the classification task. In the image below, you can see how a **residual network (resnet)** can be structured:\n",
    "\n",
    " ![](img/resnet.png)\n",
    "\n",
    " The 2 residual blocks are composed of two convolutional layers, after which the input of the first layer bypasses the whole two layers and gets summed to the output of the second layer. This bypass is called **skip connection**."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import vgg16_bn\n",
    "from torchsummary import summary\n",
    "from scripts import mnistm\n",
    "from scripts import mnist\n",
    "from scripts import train\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def _build_vgg_block(self, num_conv_layers, in_channels, out_channels, kernel_size=3, batchnorm=True, activation=nn.ReLU, maxpool=True):\n",
    "        layers = []\n",
    "        for i in range(num_conv_layers):\n",
    "            if i == 0:\n",
    "                num_channels_in = in_channels\n",
    "            else:\n",
    "                num_channels_in = out_channels\n",
    "            \n",
    "            layers.append(nn.Conv2d(in_channels=num_channels_in, out_channels=out_channels, kernel_size=kernel_size))\n",
    "            if batchnorm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(activation())\n",
    "        \n",
    "        if maxpool:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def __init__(self, num_classes=10, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            self._build_vgg_block(2, in_channels, 16, activation=nn.SiLU),\n",
    "            self._build_vgg_block(2, 16, 32, activation=nn.SiLU)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.classifier(self.avgpool(self.features(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\n├─Sequential: 1-1                        --\n|    └─Sequential: 2-1                   --\n|    |    └─Conv2d: 3-1                  448\n|    |    └─BatchNorm2d: 3-2             32\n|    |    └─SiLU: 3-3                    --\n|    |    └─Conv2d: 3-4                  2,320\n|    |    └─BatchNorm2d: 3-5             32\n|    |    └─SiLU: 3-6                    --\n|    |    └─MaxPool2d: 3-7               --\n|    └─Sequential: 2-2                   --\n|    |    └─Conv2d: 3-8                  4,640\n|    |    └─BatchNorm2d: 3-9             64\n|    |    └─SiLU: 3-10                   --\n|    |    └─Conv2d: 3-11                 9,248\n|    |    └─BatchNorm2d: 3-12            64\n|    |    └─SiLU: 3-13                   --\n|    |    └─MaxPool2d: 3-14              --\n├─AdaptiveAvgPool2d: 1-2                 --\n├─Sequential: 1-3                        --\n|    └─Flatten: 2-3                      --\n|    └─Linear: 2-4                       330\n=================================================================\nTotal params: 17,178\nTrainable params: 17,178\nNon-trainable params: 0\n=================================================================\n"
     ]
    }
   ],
   "source": [
    "net = CNN(in_channels=3)\n",
    "_ = summary(net)"
   ]
  },
  {
   "source": [
    "Test if the net works on random data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "X = torch.rand((100,3,28,28))\n",
    "y = net(X)\n",
    "y.shape"
   ]
  },
  {
   "source": [
    "Let's go more in detail in the computation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "in torch.Size([100, 3, 28, 28])\n0 torch.Size([100, 16, 12, 12])\n1 torch.Size([100, 32, 4, 4])\navgpool torch.Size([100, 32, 1, 1])\nout torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "z = X\n",
    "print(\"in\", z.shape)\n",
    "for i, mod in enumerate(net.features):\n",
    "    z = mod(z)\n",
    "    print(i, z.shape)\n",
    "\n",
    "z = net.avgpool(z)\n",
    "print(\"avgpool\", z.shape)\n",
    "\n",
    "z = net.classifier(z)\n",
    "print(\"out\", z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.4639, 0.4676, 0.4199], [0.2534, 0.2380, 0.2618]), # I pre-computed these data\n",
    "])\n",
    "\n",
    "mnistm_train = mnistm.MNISTM(root=\"datasets/MNISTM\", download=True, transform=transforms)\n",
    "mnistm_test = mnistm.MNISTM(root=\"datasets/MNISTM\", train=False, download=True, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ground truth: 5\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-12T17:26:40.853991</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pd0d2687c56)\">\n    <image height=\"218\" id=\"image31b1c4a8ab\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m51c21ecfe3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m51c21ecfe3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m51c21ecfe3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m51c21ecfe3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m51c21ecfe3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m51c21ecfe3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m51c21ecfe3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m10b630b22e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m10b630b22e\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m10b630b22e\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m10b630b22e\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m10b630b22e\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m10b630b22e\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m10b630b22e\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd0d2687c56\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "img = (mnistm_train.train_data[0].numpy() * 255).astype(\"uint8\")\n",
    "plt.imshow(img)\n",
    "print(\"Ground truth:\", mnistm_train.train_labels[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([10000, 28, 28, 3]), torch.Size([10000]))"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "mnistm_test.test_data.shape, mnistm_test.test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = 128\n",
    "batch_test = 512\n",
    "mnistm_trainloader = DataLoader(mnistm_train, batch_train, shuffle=True, num_workers=8)\n",
    "mnistm_testloader = DataLoader(mnistm_test, batch_test, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(net.parameters(), lr=0.1, weight_decay=5e-4, momentum=.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 --- learning rate 0.10000\n",
      "Epoch 1 completed. Loss - total: 39916.70584964752 - average: 0.6652784308274587; Performance: 0.7851166666666667\n",
      "Epoch 2 --- learning rate 0.10000\n",
      "Epoch 2 completed. Loss - total: 14302.629755973816 - average: 0.2383771625995636; Performance: 0.92725\n",
      "Epoch 3 --- learning rate 0.10000\n",
      "Epoch 3 completed. Loss - total: 11274.251604557037 - average: 0.18790419340928396; Performance: 0.9429\n",
      "Epoch 4 --- learning rate 0.10000\n",
      "Epoch 4 completed. Loss - total: 10188.28065109253 - average: 0.16980467751820882; Performance: 0.9482\n",
      "Epoch 5 --- learning rate 0.10000\n",
      "Epoch 5 completed. Loss - total: 9535.263808250427 - average: 0.15892106347084045; Performance: 0.9522666666666667\n",
      "Epoch 6 --- learning rate 0.10000\n",
      "Epoch 6 completed. Loss - total: 9109.877534151077 - average: 0.1518312922358513; Performance: 0.9540666666666666\n",
      "Epoch 7 --- learning rate 0.10000\n",
      "Epoch 7 completed. Loss - total: 8784.52181816101 - average: 0.1464086969693502; Performance: 0.9562166666666667\n",
      "Epoch 8 --- learning rate 0.10000\n",
      "Epoch 8 completed. Loss - total: 8707.463371753693 - average: 0.1451243895292282; Performance: 0.9554\n",
      "Epoch 9 --- learning rate 0.10000\n",
      "Epoch 9 completed. Loss - total: 8417.334141731262 - average: 0.1402889023621877; Performance: 0.9571333333333333\n",
      "Epoch 10 --- learning rate 0.10000\n",
      "Epoch 10 completed. Loss - total: 8215.824211597443 - average: 0.13693040352662406; Performance: 0.95865\n",
      "Epoch 11 --- learning rate 0.10000\n",
      "Epoch 11 completed. Loss - total: 8350.245857954025 - average: 0.13917076429923375; Performance: 0.9580166666666666\n",
      "Epoch 12 --- learning rate 0.10000\n",
      "Epoch 12 completed. Loss - total: 8185.631074428558 - average: 0.1364271845738093; Performance: 0.9593333333333334\n",
      "Epoch 13 --- learning rate 0.01000\n",
      "Epoch 13 completed. Loss - total: 4893.495178461075 - average: 0.08155825297435125; Performance: 0.9782166666666666\n",
      "Epoch 14 --- learning rate 0.01000\n",
      "Epoch 14 completed. Loss - total: 4254.821068525314 - average: 0.0709136844754219; Performance: 0.9814666666666667\n",
      "Epoch 15 --- learning rate 0.01000\n",
      "Epoch 15 completed. Loss - total: 4058.985941052437 - average: 0.06764976568420727; Performance: 0.9823\n",
      "Epoch 16 --- learning rate 0.01000\n",
      "Epoch 16 completed. Loss - total: 3933.1740429401398 - average: 0.065552900715669; Performance: 0.98285\n",
      "Epoch 17 --- learning rate 0.01000\n",
      "Epoch 17 completed. Loss - total: 3881.279410004616 - average: 0.06468799016674359; Performance: 0.9835666666666667\n",
      "Epoch 18 --- learning rate 0.01000\n",
      "Epoch 18 completed. Loss - total: 3860.814036488533 - average: 0.06434690060814222; Performance: 0.9832833333333333\n",
      "Epoch 19 --- learning rate 0.01000\n",
      "Epoch 19 completed. Loss - total: 3760.2532898187637 - average: 0.06267088816364606; Performance: 0.9840166666666667\n",
      "Epoch 20 --- learning rate 0.01000\n",
      "Epoch 20 completed. Loss - total: 3761.9713264107704 - average: 0.06269952210684618; Performance: 0.9840333333333333\n",
      "Epoch 21 --- learning rate 0.01000\n",
      "Epoch 21 completed. Loss - total: 3715.6659158468246 - average: 0.06192776526411375; Performance: 0.9848666666666667\n",
      "Epoch 22 --- learning rate 0.01000\n",
      "Epoch 22 completed. Loss - total: 3734.5519214868546 - average: 0.06224253202478091; Performance: 0.9843333333333333\n",
      "Epoch 23 --- learning rate 0.01000\n",
      "Epoch 23 completed. Loss - total: 3673.969829082489 - average: 0.06123283048470815; Performance: 0.9845666666666667\n",
      "Epoch 24 --- learning rate 0.01000\n",
      "Epoch 24 completed. Loss - total: 3695.95804977417 - average: 0.0615993008295695; Performance: 0.98495\n",
      "Epoch 25 --- learning rate 0.00100\n",
      "Epoch 25 completed. Loss - total: 3144.5695699453354 - average: 0.05240949283242226; Performance: 0.9884833333333334\n",
      "Epoch 26 --- learning rate 0.00100\n",
      "Epoch 26 completed. Loss - total: 3073.26805973053 - average: 0.05122113432884216; Performance: 0.9890666666666666\n",
      "Epoch 27 --- learning rate 0.00100\n",
      "Epoch 27 completed. Loss - total: 3037.3990335464478 - average: 0.05062331722577413; Performance: 0.9889833333333333\n",
      "Epoch 28 --- learning rate 0.00100\n",
      "Epoch 28 completed. Loss - total: 3035.031568169594 - average: 0.05058385946949323; Performance: 0.98905\n",
      "Epoch 29 --- learning rate 0.00100\n",
      "Epoch 29 completed. Loss - total: 3015.38572537899 - average: 0.0502564287563165; Performance: 0.9892\n",
      "Epoch 30 --- learning rate 0.00100\n",
      "Epoch 30 completed. Loss - total: 3011.784267306328 - average: 0.05019640445510546; Performance: 0.9891666666666666\n",
      "Epoch 31 --- learning rate 0.00100\n",
      "Epoch 31 completed. Loss - total: 2982.126230120659 - average: 0.04970210383534431; Performance: 0.9896833333333334\n",
      "Epoch 32 --- learning rate 0.00100\n",
      "Epoch 32 completed. Loss - total: 2998.855155467987 - average: 0.04998091925779979; Performance: 0.9889666666666667\n",
      "Epoch 33 --- learning rate 0.00100\n",
      "Epoch 33 completed. Loss - total: 2964.2032507658005 - average: 0.04940338751276334; Performance: 0.9892666666666666\n",
      "Epoch 34 --- learning rate 0.00100\n",
      "Epoch 34 completed. Loss - total: 2938.436429142952 - average: 0.048973940485715864; Performance: 0.9898\n",
      "Epoch 35 --- learning rate 0.00100\n",
      "Epoch 35 completed. Loss - total: 2957.2788326740265 - average: 0.04928798054456711; Performance: 0.9894333333333334\n",
      "Epoch 36 --- learning rate 0.00100\n",
      "Epoch 36 completed. Loss - total: 2951.6055450439453 - average: 0.04919342575073242; Performance: 0.9897833333333333\n",
      "Epoch 37 --- learning rate 0.00010\n",
      "Epoch 37 completed. Loss - total: 2874.52219748497 - average: 0.047908703291416166; Performance: 0.9901833333333333\n",
      "Epoch 38 --- learning rate 0.00010\n",
      "Epoch 38 completed. Loss - total: 2879.6681136488914 - average: 0.04799446856081486; Performance: 0.9901833333333333\n",
      "Epoch 39 --- learning rate 0.00010\n",
      "Epoch 39 completed. Loss - total: 2867.386199951172 - average: 0.047789769999186195; Performance: 0.9903\n",
      "Epoch 40 --- learning rate 0.00010\n",
      "Epoch 40 completed. Loss - total: 2852.5520498752594 - average: 0.04754253416458765; Performance: 0.9901833333333333\n",
      "Epoch 41 --- learning rate 0.00010\n",
      "Epoch 41 completed. Loss - total: 2894.986396431923 - average: 0.048249773273865385; Performance: 0.9898\n",
      "Epoch 42 --- learning rate 0.00010\n",
      "Epoch 42 completed. Loss - total: 2837.0237288475037 - average: 0.04728372881412506; Performance: 0.9903166666666666\n",
      "Epoch 43 --- learning rate 0.00010\n",
      "Epoch 43 completed. Loss - total: 2872.85069334507 - average: 0.0478808448890845; Performance: 0.9904666666666667\n",
      "Epoch 44 --- learning rate 0.00010\n",
      "Epoch 44 completed. Loss - total: 2848.5466269254684 - average: 0.04747577711542447; Performance: 0.9904666666666667\n",
      "Epoch 45 --- learning rate 0.00010\n",
      "Epoch 45 completed. Loss - total: 2868.335666656494 - average: 0.0478055944442749; Performance: 0.9904166666666666\n",
      "Epoch 46 --- learning rate 0.00010\n",
      "Epoch 46 completed. Loss - total: 2873.422217488289 - average: 0.04789037029147148; Performance: 0.9904833333333334\n",
      "Epoch 47 --- learning rate 0.00010\n",
      "Epoch 47 completed. Loss - total: 2855.2293285131454 - average: 0.04758715547521909; Performance: 0.98995\n",
      "Epoch 48 --- learning rate 0.00010\n",
      "Epoch 48 completed. Loss - total: 2861.1678911447525 - average: 0.04768613151907921; Performance: 0.99025\n",
      "Epoch 49 --- learning rate 0.00001\n",
      "Epoch 49 completed. Loss - total: 2870.0329595804214 - average: 0.04783388265967369; Performance: 0.9899\n",
      "Epoch 50 --- learning rate 0.00001\n",
      "Epoch 50 completed. Loss - total: 2851.5374298095703 - average: 0.04752562383015951; Performance: 0.9902833333333333\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2851.5374298095703, 0.9902833333333333)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "train.train_model(net, mnistm_trainloader, loss_fn=nn.CrossEntropyLoss(), optimizer=optim, num_epochs=50, lr_scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"models_push/cnn_mnistm/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"models_push/cnn_mnistm/model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TESTING - loss -- - performance 0.979\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, 0.979)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train.test_model(net, mnistm_testloader)"
   ]
  },
  {
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Transfer Learning (TL) is the utilization of a model, built for a given task (**upstream task**) on one or more different tasks (**downstream task**).\n",
    "\n",
    "We might find oursevles in different situations:\n",
    "\n",
    "1. we might just re-use the model for the upstream task without re-training\n",
    "2. we might want to re-train the model on the downstream task (with some constraints)\n",
    "3. we might want to fully re-train the model, using the `state_dict` from the upstream task as an **initialization** for the training on the downstream task\n",
    "\n",
    "Note that these options are possible only if the upstream task and the downstream tasks are in a way *relatable* (the number of classes is the same).\n",
    "\n",
    "Also, in some configurations there may be issues when the images of the upstream task have a different size than those of the downstream task.\n",
    "\n",
    "In these cases, I need to **re-adapt the network** by modifying neurons in the output layer or by toggling the number of incoming units in given layers.\n",
    "\n",
    "#### Re-use the same model on MNIST\n",
    "\n",
    "Basically, we wish to do this:\n",
    "\n",
    "![](img/tl1.jpg)\n",
    "\n",
    "We just need to import MNIST."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "_, _, mnist_train, mnist_test = mnist.get_data()\n",
    "mnist_train.data.shape"
   ]
  },
  {
   "source": [
    "Have a look at the shape.\n",
    "\n",
    "**Q**: What do we need to do?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_3(torch.utils.data.Dataset):\n",
    "    def __init__(self, mnist_dataset, transform=None):\n",
    "        n, h, w = mnist_dataset.data.shape\n",
    "        self.data = mnist_dataset.data.clone().unsqueeze(1).expand(n, 3, h, w)\n",
    "        self.targets = mnist_dataset.targets.clone()\n",
    "        if transform is None:\n",
    "            self.transform = lambda x: x\n",
    "        else:\n",
    "            self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.data[index]), self.targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_mnist = T.Compose([\n",
    "    lambda x: x/255,\n",
    "    T.Normalize([0.1307, 0.1307, 0.1307], [0.3081, 0.3081, 0.3081])\n",
    "])\n",
    "mnist3_train = MNIST_3(mnist_train, transforms_mnist)\n",
    "mnist3_test = MNIST_3(mnist_test, transforms_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb3e8ac0490>"
      ]
     },
     "metadata": {},
     "execution_count": 74
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-12T18:41:18.331660</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p5a6f338664)\">\n    <image height=\"218\" id=\"image18a937e0f1\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m2e40fefe23\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m2e40fefe23\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m2e40fefe23\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m2e40fefe23\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m2e40fefe23\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m2e40fefe23\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m2e40fefe23\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mf52eb69da8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf52eb69da8\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf52eb69da8\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf52eb69da8\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf52eb69da8\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf52eb69da8\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mf52eb69da8\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p5a6f338664\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(mnist3_train.data[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainloader = DataLoader(mnist3_train, 512, shuffle=False, num_workers=0)\n",
    "mnist_testloader = DataLoader(mnist3_test, 512, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TESTING - loss -- - performance 0.8295833333333333\n",
      "TESTING - loss -- - performance 0.8285\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, 0.8285)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "train.test_model(net, mnist_trainloader)\n",
    "train.test_model(net, mnist_testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using downloaded and verified file: datasets/CIFAR/cifar-10-python.tar.gz\n",
      "Extracting datasets/CIFAR/cifar-10-python.tar.gz to datasets/CIFAR\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_cifar = T.Compose([T.ToTensor(), T.Normalize([0.4913997551666284, 0.48215855929893703, 0.4465309133731618], [0.24703225141799082, 0.24348516474564, 0.26158783926049628])])\n",
    "\n",
    "cifar_train = CIFAR10(\"datasets/CIFAR\", train=True, transform=transform_cifar, download=True)\n",
    "cifar_test = CIFAR10(\"datasets/CIFAR\", train=False, transform=transform_cifar, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_trainloader = DataLoader(cifar_train, batch_size=128, shuffle=True)\n",
    "cifar_testloader = DataLoader(cifar_test, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of trainset (50000, 32, 32, 3)\nNum classes 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of trainset\", cifar_train.data.shape)\n",
    "print(\"Num classes\", max(cifar_test.targets) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = vgg16_bn(pretrained=True)\n",
    "vgg.classifier[-1].out_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TESTING - loss -- - performance 0.0003\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, 0.0003)"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "train.test_model(vgg, cifar_testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze training in almost all layers\n",
    "for name, param in vgg.named_parameters():\n",
    "    if \"classifier.6\" not in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "features.0.weight False\nfeatures.0.bias False\nfeatures.1.weight False\nfeatures.1.bias False\nfeatures.3.weight False\nfeatures.3.bias False\nfeatures.4.weight False\nfeatures.4.bias False\nfeatures.7.weight False\nfeatures.7.bias False\nfeatures.8.weight False\nfeatures.8.bias False\nfeatures.10.weight False\nfeatures.10.bias False\nfeatures.11.weight False\nfeatures.11.bias False\nfeatures.14.weight False\nfeatures.14.bias False\nfeatures.15.weight False\nfeatures.15.bias False\nfeatures.17.weight False\nfeatures.17.bias False\nfeatures.18.weight False\nfeatures.18.bias False\nfeatures.20.weight False\nfeatures.20.bias False\nfeatures.21.weight False\nfeatures.21.bias False\nfeatures.24.weight False\nfeatures.24.bias False\nfeatures.25.weight False\nfeatures.25.bias False\nfeatures.27.weight False\nfeatures.27.bias False\nfeatures.28.weight False\nfeatures.28.bias False\nfeatures.30.weight False\nfeatures.30.bias False\nfeatures.31.weight False\nfeatures.31.bias False\nfeatures.34.weight False\nfeatures.34.bias False\nfeatures.35.weight False\nfeatures.35.bias False\nfeatures.37.weight False\nfeatures.37.bias False\nfeatures.38.weight False\nfeatures.38.bias False\nfeatures.40.weight False\nfeatures.40.bias False\nfeatures.41.weight False\nfeatures.41.bias False\nclassifier.0.weight False\nclassifier.0.bias False\nclassifier.3.weight False\nclassifier.3.bias False\nclassifier.6.weight True\nclassifier.6.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in vgg.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 --- learning rate 0.00100\n",
      "Epoch 1 completed. Loss - total: 104514.88572311401 - average: 2.09029771446228; Performance: 0.39444\n",
      "Epoch 2 --- learning rate 0.00100\n",
      "Epoch 2 completed. Loss - total: 82215.03775596619 - average: 1.6443007551193238; Performance: 0.45688\n",
      "Epoch 3 --- learning rate 0.00100\n",
      "Epoch 3 completed. Loss - total: 82082.87772369385 - average: 1.641657554473877; Performance: 0.45366\n",
      "Epoch 4 --- learning rate 0.00100\n",
      "Epoch 4 completed. Loss - total: 82183.42641067505 - average: 1.643668528213501; Performance: 0.46088\n",
      "Epoch 5 --- learning rate 0.00100\n",
      "Epoch 5 completed. Loss - total: 82216.7146434784 - average: 1.644334292869568; Performance: 0.4589\n",
      "Epoch 6 --- learning rate 0.00100\n",
      "Epoch 6 completed. Loss - total: 82022.21513366699 - average: 1.6404443026733397; Performance: 0.46338\n",
      "Epoch 7 --- learning rate 0.00100\n",
      "Epoch 7 completed. Loss - total: 83208.70336914062 - average: 1.6641740673828125; Performance: 0.45666\n",
      "Epoch 8 --- learning rate 0.00100\n",
      "Epoch 8 completed. Loss - total: 82473.63500785828 - average: 1.6494727001571656; Performance: 0.46158\n",
      "Epoch 9 --- learning rate 0.00100\n",
      "Epoch 9 completed. Loss - total: 82293.5652885437 - average: 1.645871305770874; Performance: 0.46368\n",
      "Epoch 10 --- learning rate 0.00100\n",
      "Epoch 10 completed. Loss - total: 82953.93154525757 - average: 1.6590786309051513; Performance: 0.45836\n",
      "Epoch 11 --- learning rate 0.00100\n",
      "Epoch 11 completed. Loss - total: 82222.36985778809 - average: 1.6444473971557618; Performance: 0.4626\n",
      "Epoch 12 --- learning rate 0.00100\n",
      "Epoch 12 completed. Loss - total: 82730.33647537231 - average: 1.6546067295074462; Performance: 0.46144\n",
      "Epoch 13 --- learning rate 0.00100\n",
      "Epoch 13 completed. Loss - total: 82307.69012069702 - average: 1.6461538024139404; Performance: 0.46056\n",
      "Epoch 14 --- learning rate 0.00100\n",
      "Epoch 14 completed. Loss - total: 82341.80981063843 - average: 1.6468361962127684; Performance: 0.46094\n",
      "Epoch 15 --- learning rate 0.00100\n",
      "Epoch 15 completed. Loss - total: 82381.61346244812 - average: 1.6476322692489624; Performance: 0.46448\n",
      "Epoch 16 --- learning rate 0.00100\n",
      "Epoch 16 completed. Loss - total: 83300.13749885559 - average: 1.6660027499771117; Performance: 0.4569\n",
      "Epoch 17 --- learning rate 0.00100\n",
      "Epoch 17 completed. Loss - total: 82461.52586174011 - average: 1.6492305172348023; Performance: 0.46332\n",
      "Epoch 18 --- learning rate 0.00100\n",
      "Epoch 18 completed. Loss - total: 82779.96165657043 - average: 1.6555992331314087; Performance: 0.4607\n",
      "Epoch 19 --- learning rate 0.00100\n",
      "Epoch 19 completed. Loss - total: 82441.98490715027 - average: 1.6488396981430054; Performance: 0.4623\n",
      "Epoch 20 --- learning rate 0.00100\n",
      "Epoch 20 completed. Loss - total: 82190.5898475647 - average: 1.643811796951294; Performance: 0.46264\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(82190.5898475647, 0.46264)"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(vgg.parameters())\n",
    "train.train_model(vgg, cifar_trainloader, nn.CrossEntropyLoss(), optimizer, 20)"
   ]
  }
 ]
}