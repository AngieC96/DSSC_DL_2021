{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Deep Learning course - LAB 4\n",
    "\n",
    "## A tour of the optimizers in PyTorch\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Recap from previous Lab\n",
    "\n",
    "* We experimented with building a Multilayer Perceptron (MLP) trained on the MNIST dataset using _vanilla_ Stochastic Gradient Descent (SGD) and constructing a training loop that lets us track loss and accuracy as training goes on\n",
    "* We saw how we can analyze parameters and gradients of this MLP as training is operated\n",
    "* We explored how to add regularization to our network and loss function to increase generalization or speed up the training\n",
    "\n",
    "### Agenda for today\n",
    "\n",
    "* Today we will be taking a quick tour of the `torch.optim` library, having a look at some optimizers which are more advanced than vanilla SGD\n",
    "* in addition to that, we will be exploring how to toggle the hyperparameters (chiefly, the learning rate) of the optimizer as the training is operated"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# TODO\n",
    "\n",
    "talk about the effect of the minibatch size as a regularizer\n",
    "\n",
    "talk about gradient clipping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scripts.architectures import MLP # I have pasted the code for the MLP with regularization in this script, no need to redefine it\n",
    "from scripts.train_utils import AverageMeter, accuracy\n",
    "from scripts import mnist"
   ]
  },
  {
   "source": [
    "### Exploring optimizers in PyTorch\n",
    "\n",
    "PT optimizers can be found in the `torch.optim` library.\n",
    "\n",
    "We'll take a look at some of those, namely:\n",
    "\n",
    "* SGD with momentum\n",
    "* RMSProp\n",
    "* Adam\n",
    "\n",
    "If you're a fan of optimizers, you can yourself have a look at the plethora of optimizers in the `optim` library on the [official docs](https://pytorch.org/docs/stable/optim.html).\n",
    "\n",
    "#### SGD w/ momentum\n",
    "\n",
    "Actually, SGD with momentum is part of vanilla SGD in PT. Indeed, one of its arguments is `momentum`. Good values for momentum are usually high (close to 1).\n",
    "\n",
    "![](img/sgd_momentum.jpg)\n",
    "\n",
    "*Image from Deep Learning book (Goodfellow et al.) - chapter 8.3.2*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .1\n",
    "wd = 5e-4\n",
    "momentum = .9\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model = MLP()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)"
   ]
  },
  {
   "source": [
    "Let us also recover the training and testing routines we defined last lab (without the trajectory):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, loss_fn, optimizer, loss_meter, performance_meter, performance): # note: I've added a generic performance to replace accuracy\n",
    "    for X, y in dataloader:\n",
    "        # 1. reset the gradients previously accumulated by the optimizer\n",
    "        #    this will avoid re-using gradients from previous loops\n",
    "        optimizer.zero_grad() \n",
    "        # 2. get the predictions from the current state of the model\n",
    "        #    this is the forward pass\n",
    "        y_hat = model(X)\n",
    "        # 3. calculate the loss on the current mini-batch\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        # 4. execute the backward pass given the current loss\n",
    "        loss.backward()\n",
    "        # 5. update the value of the params\n",
    "        optimizer.step()\n",
    "        # 6. calculate the accuracy for this mini-batch\n",
    "        acc = performance(y_hat, y)\n",
    "        # 7. update the loss and accuracy AverageMeter\n",
    "        loss_meter.update(val=loss.item(), n=X.shape[0])\n",
    "        performance_meter.update(val=acc, n=X.shape[0])\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, loss_fn, optimizer, num_epochs, checkpoint_loc=None, checkpoint_name=\"checkpoint.pt\", performance=accuracy): # note: I've added a generic performance to replace accuracy and an object where to store the trajectory\n",
    "\n",
    "    # create the folder for the checkpoints (if it's not None)\n",
    "    if checkpoint_loc is not None:\n",
    "        os.makedirs(checkpoint_loc, exist_ok=True)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    # epoch loop\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_meter = AverageMeter()\n",
    "        performance_meter = AverageMeter()\n",
    "\n",
    "        train_epoch(model, dataloader, loss_fn, optimizer, loss_meter, performance_meter, performance)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} completed. Loss - total: {loss_meter.sum} - average: {loss_meter.avg}; Performance: {performance_meter.avg}\")\n",
    "\n",
    "        # produce checkpoint dictionary -- but only if the name and folder of the checkpoint are not None\n",
    "        if checkpoint_name is not None and checkpoint_loc is not None:\n",
    "            checkpoint_dict = {\n",
    "                \"parameters\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch\n",
    "            }\n",
    "            torch.save(checkpoint_dict, os.path.join(checkpoint_loc, checkpoint_name))\n",
    "\n",
    "    return loss_meter.sum, performance_meter.avg\n",
    "\n",
    "def test_model(model, dataloader, performance=accuracy, loss_fn=None):\n",
    "    # create an AverageMeter for the loss if passed\n",
    "    if loss_fn is not None:\n",
    "        loss_meter = AverageMeter()\n",
    "    \n",
    "    performance_meter = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            y_hat = model(X)\n",
    "            loss = loss_fn(y_hat, y) if loss_fn is not None else None\n",
    "            acc = performance(y_hat, y)\n",
    "            if loss_fn is not None:\n",
    "                loss_meter.update(loss.item(), X.shape[0])\n",
    "            performance_meter.update(acc, X.shape[0])\n",
    "    # get final performances\n",
    "    fin_loss = loss_meter.sum if loss_fn is not None else None\n",
    "    fin_perf = performance_meter.avg\n",
    "    print(f\"TESTING - loss {fin_loss if fin_loss is not None else '--'} - performance {fin_perf}\")\n",
    "    return fin_loss, fin_perf"
   ]
  },
  {
   "source": [
    "and recover the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader, _, _ = mnist.get_data()"
   ]
  },
  {
   "source": [
    "Let's train the network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 completed. Loss - total: 26499.092242240906 - average: 0.44165153737068175; Performance: 0.8647500000317891\n",
      "Epoch 2 completed. Loss - total: 14802.4463763237 - average: 0.246707439605395; Performance: 0.9258000000317892\n",
      "Epoch 3 completed. Loss - total: 13043.869870185852 - average: 0.2173978311697642; Performance: 0.9346833333333333\n",
      "Epoch 4 completed. Loss - total: 11759.672103881836 - average: 0.19599453506469727; Performance: 0.9414\n",
      "Epoch 5 completed. Loss - total: 11193.425158977509 - average: 0.18655708598295848; Performance: 0.9434833333015442\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'trajectory' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a641dd16d7cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-2ae50da05c09>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, loss_fn, optimizer, num_epochs, checkpoint_loc, checkpoint_name, performance)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperformance_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trajectory' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(model, trainloader, loss_fn, optimizer, num_epochs)"
   ]
  },
  {
   "source": [
    "by adding the momentum term, we already saw a small increase in training accuracy. Let's test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TESTING - loss -- - performance 0.9569333333333333\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, 0.9569333333333333)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "test_model(model, testloader)"
   ]
  },
  {
   "source": [
    "#### RMSProp and the LR sensitivity \"dilemma\"\n",
    "\n",
    "With RMSProp we want to tackle a problem with SGD/SGD+momentum, which is related to the fact that, with SGD, there seems to be a deal of _sensitivity_ towards some specific _directions_ (read, parameters, since each parameter of the model represent a dimension in the optimization space).\n",
    "\n",
    "RMSProp tries to tackle this issue by introducing an _adaptive rule_ for updating the learning rate parameter-wise in each step. \n",
    "In particular:\n",
    "* it keeps track of the _history_ of the squared gradient via an exponentially decaying running average \n",
    "  * (the _decay_ is controlled by a hyperparameter $\\rho \\in (0,1)$)\n",
    "* The parameter update is \n",
    "  * directly proportional to the learning rate\n",
    "  * directly proportional to the gradient for this step\n",
    "  * inversely proportional to the gradient average\n",
    "    * i.e., the direct effect of the gradient is _mitigated_ by dividing it with the accumulated average gradient\n",
    "\n",
    "The formula for the update is:\n",
    "\n",
    "$ \\theta_{t+1} = \\theta_t + \\frac{\\text{lr}}{\\sqrt{\\epsilon + \\mathbf{R}(\\rho)}} \\odot \\mathbf{G}$\n",
    "\n",
    "where:\n",
    "* $\\epsilon$ is a small constant for numerical stability\n",
    "* $\\mathbf{R}(\\rho)$ is the squared gradient running averate (which depends upon $\\rho$)\n",
    "* $\\mathbf{G}$ is the gradient for the current step"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP() # always remember to reinstantiate the net between tries\n",
    "rmsprop = torch.optim.RMSprop(model.parameters()) # let's use the default hyperparams (lr=.01, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 completed. Loss - total: 25307.13468837738 - average: 0.42178557813962303; Performance: 0.8705166666984558\n",
      "Epoch 2 completed. Loss - total: 16272.398222923279 - average: 0.27120663704872133; Performance: 0.9179166666984558\n",
      "Epoch 3 completed. Loss - total: 14396.38200044632 - average: 0.23993970000743867; Performance: 0.9285000000317891\n",
      "Epoch 4 completed. Loss - total: 13521.132495880127 - average: 0.22535220826466879; Performance: 0.9339333333651225\n",
      "Epoch 5 completed. Loss - total: 12783.330872535706 - average: 0.21305551454226176; Performance: 0.9366666666666666\n",
      "TESTING - loss -- - performance 0.9390000000317892\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, 0.9390000000317892)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "train_model(model, trainloader, loss_fn, rmsprop, num_epochs)\n",
    "test_model(model, testloader)"
   ]
  },
  {
   "source": [
    "#### ADAM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "adam = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 completed. Loss - total: 48566.915053367615 - average: 0.8094485842227935; Performance: 0.8016000000317891\n",
      "Epoch 2 completed. Loss - total: 18961.944045066833 - average: 0.3160324007511139; Performance: 0.9128166666666667\n",
      "Epoch 3 completed. Loss - total: 15120.141127586365 - average: 0.2520023521264394; Performance: 0.9276666666348775\n",
      "Epoch 4 completed. Loss - total: 13185.002179145813 - average: 0.21975003631909687; Performance: 0.9350666666348775\n",
      "Epoch 5 completed. Loss - total: 12003.2468252182 - average: 0.2000541137536367; Performance: 0.9411\n",
      "TESTING - loss -- - performance 0.9559833333651224\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, 0.9559833333651224)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "train_model(model, trainloader, loss_fn, adam, num_epochs)\n",
    "test_model(model, testloader)"
   ]
  },
  {
   "source": [
    "static nature of the learning rate (LR):\n",
    "* if the LR is too high, we'll notice a sharp increase in accuracy with a relatively quick plateu corresponding to non-optimal solutions.\n",
    "  * this is because we'll likely miss local optima because our step in the parameter space is too large\n",
    "* if the LR is too low, training will be excruciatingly low and we'll likely get stuck in very bad local optima, being unable to get out of them because the step in the parameter space is too low to get out of these _valleys_\n",
    "\n",
    "An _ideal_ solution would be to keep a _high enough_ LR until we find a _good enough_ portion of the parameter space, then decrease progressively the LR in order to carefully explore these areas for good optima."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### References\n",
    "\n",
    "[1](https://www.deeplearningbook.org/) LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. nature, 521(7553), 436-444."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}