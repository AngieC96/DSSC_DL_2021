{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "As for homework 1, try to write your solution in a Jupyter Notebook trying to explain your choices using comments or (preferably) the markdown cells. For this homework, Python scripts will be accepted as well.\n",
    "\n",
    "\n",
    "Reconstruct in PyTorch the first experiment in [Learning representations by back-propagating errors](https://www.nature.com/articles/323533a0) with learning rule in eq.8 (gradient descent without momentum) ([alternative link to paper](https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf)).\n",
    "\n",
    "Try to be as close as possible to the original protocol, except for what regards the learning rule, and perhaps the random initialization method\n",
    "\n",
    "1. Read the paper (don’t worry if you don’t understand the other experiments in detail, because our focus is on the first one)\n",
    "\n",
    "2. Create the data, the model and everything is needed (do not use dataloaders if you don’t know yet how they work)\n",
    "\n",
    "3. Train the model\n",
    "\n",
    "4. Inspect the weights you obtained and check if they provide a solution to the problem\n",
    "\n",
    "Compare the solution to the solution reported in the paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 2\n",
    "\n",
    "We will reproduce the experiment in Fig. 1 of the paper.\n",
    "\n",
    "We want to detect myrror symmetry in the input vectors. Since we have 6 nodes in the inuts units our vectors will have 6 elements in each vector, which will be $1$ or $0$. We will have $64$ possible input vectors.\n",
    "\n",
    "Since we have two hidden units, we will have one layer with two nodes, both having the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Dataset handling\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Permutation building\n",
    "from itertools import product"
   ]
  },
  {
   "source": [
    "We will generate all the 64 possible vectors long 6 of $0$ or $1$ digits."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([item for item in product([0, 1], repeat=6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\ntensor([0., 0., 1., 1., 0., 0.])\ntensor([0., 1., 0., 0., 1., 0.])\ntensor([0., 1., 1., 1., 1., 0.])\ntensor([1., 0., 0., 0., 0., 1.])\ntensor([1., 0., 1., 1., 0., 1.])\ntensor([1., 1., 0., 0., 1., 1.])\ntensor([1., 1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "flag = 1\n",
    "y = torch.zeros((leng, 1))\n",
    "for j in range(leng):\n",
    "    for i in range(3):\n",
    "        if X[j][i] != X[j][5-i]:\n",
    "            flag = 0\n",
    "    if flag == 1:\n",
    "        y[j] = 1\n",
    "        print(X[j])\n",
    "    flag = 1\n",
    "\n",
    "y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(X, y)\n",
    "trainloader = DataLoader(train, batch_size=leng, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1  # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(in_features =  6, out_features = 2, bias = True)\n",
    "        self.layer2 = torch.nn.Linear(in_features =  2, out_features = 1, bias = True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.layer1(X)\n",
    "        out = torch.sigmoid(out)\n",
    "        out = self.layer2(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    '''\n",
    "    y_hat is the model output - a Tensor of shape (n x num_classes)\n",
    "    y is the ground truth\n",
    "\n",
    "    How can we implement this function?\n",
    "    '''\n",
    "    classes_prediction = y_hat.argmax(dim=1)\n",
    "    match_ground_truth = classes_prediction == y # -> tensor of booleans\n",
    "    correct_matches = match_ground_truth.sum()\n",
    "    return (correct_matches / y_hat.shape[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, loss_fn, optimizer, loss_meter, accuracy_meter):\n",
    "    for X, y in dataloader:\n",
    "        # 1. reset the gradients previously accumulated by the optimizer\n",
    "        #    this will avoid re-using gradients from previous loops\n",
    "        optimizer.zero_grad()\n",
    "        # 2. get the predictions from the current state of the model\n",
    "        #    this is the forward pass\n",
    "        y_hat = model(X)\n",
    "        # 3. calculate the loss on the current mini-batch\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        # 4. execute the backward pass given the current loss\n",
    "        loss.backward()\n",
    "        # 5. update the value of the params\n",
    "        optimizer.step()\n",
    "        # 6. calculate the accuracy for this mini-batch\n",
    "        acc = accuracy(y_hat, y)\n",
    "        # 7. update the loss and accuracy AverageMeter\n",
    "        loss_meter.update(val=loss.item(), n=X.shape[0])\n",
    "        accuracy_meter.update(val=acc, n=X.shape[0])\n",
    "\n",
    "def train_model(model, dataloader, loss_fn, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_meter = AverageMeter()\n",
    "        accuracy_meter = AverageMeter()\n",
    "        train_epoch(model, dataloader, loss_fn, optimizer, loss_meter, accuracy_meter)\n",
    "        # now with loss meter we can print both the cumulative value and the average value\n",
    "        print(f\"Epoch {epoch+1} completed. Loss - total: {loss_meter.sum} - average: {loss_meter.avg}; Accuracy: {accuracy_meter.avg}\")\n",
    "    # we also return the stats for the final epoch of training\n",
    "    return loss_meter.sum, accuracy_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "605957 - average: 0.10939176380634308; Accuracy: 56.0\n",
      "Epoch 802 completed. Loss - total: 7.001069068908691 - average: 0.1093917042016983; Accuracy: 56.0\n",
      "Epoch 803 completed. Loss - total: 7.001065731048584 - average: 0.10939165204763412; Accuracy: 56.0\n",
      "Epoch 804 completed. Loss - total: 7.001063346862793 - average: 0.10939161479473114; Accuracy: 56.0\n",
      "Epoch 805 completed. Loss - total: 7.001059055328369 - average: 0.10939154773950577; Accuracy: 56.0\n",
      "Epoch 806 completed. Loss - total: 7.001055717468262 - average: 0.10939149558544159; Accuracy: 56.0\n",
      "Epoch 807 completed. Loss - total: 7.0010528564453125 - average: 0.10939145088195801; Accuracy: 56.0\n",
      "Epoch 808 completed. Loss - total: 7.001049518585205 - average: 0.10939139872789383; Accuracy: 56.0\n",
      "Epoch 809 completed. Loss - total: 7.001046180725098 - average: 0.10939134657382965; Accuracy: 56.0\n",
      "Epoch 810 completed. Loss - total: 7.00104284286499 - average: 0.10939129441976547; Accuracy: 56.0\n",
      "Epoch 811 completed. Loss - total: 7.001039505004883 - average: 0.1093912422657013; Accuracy: 56.0\n",
      "Epoch 812 completed. Loss - total: 7.001036643981934 - average: 0.10939119756221771; Accuracy: 56.0\n",
      "Epoch 813 completed. Loss - total: 7.001033306121826 - average: 0.10939114540815353; Accuracy: 56.0\n",
      "Epoch 814 completed. Loss - total: 7.001030921936035 - average: 0.10939110815525055; Accuracy: 56.0\n",
      "Epoch 815 completed. Loss - total: 7.0010271072387695 - average: 0.10939104855060577; Accuracy: 56.0\n",
      "Epoch 816 completed. Loss - total: 7.00102424621582 - average: 0.10939100384712219; Accuracy: 56.0\n",
      "Epoch 817 completed. Loss - total: 7.001021385192871 - average: 0.10939095914363861; Accuracy: 56.0\n",
      "Epoch 818 completed. Loss - total: 7.0010175704956055 - average: 0.10939089953899384; Accuracy: 56.0\n",
      "Epoch 819 completed. Loss - total: 7.001015663146973 - average: 0.10939086973667145; Accuracy: 56.0\n",
      "Epoch 820 completed. Loss - total: 7.001012325286865 - average: 0.10939081758260727; Accuracy: 56.0\n",
      "Epoch 821 completed. Loss - total: 7.001009941101074 - average: 0.10939078032970428; Accuracy: 56.0\n",
      "Epoch 822 completed. Loss - total: 7.001006126403809 - average: 0.10939072072505951; Accuracy: 56.0\n",
      "Epoch 823 completed. Loss - total: 7.001003265380859 - average: 0.10939067602157593; Accuracy: 56.0\n",
      "Epoch 824 completed. Loss - total: 7.00100040435791 - average: 0.10939063131809235; Accuracy: 56.0\n",
      "Epoch 825 completed. Loss - total: 7.000998020172119 - average: 0.10939059406518936; Accuracy: 56.0\n",
      "Epoch 826 completed. Loss - total: 7.00099515914917 - average: 0.10939054936170578; Accuracy: 56.0\n",
      "Epoch 827 completed. Loss - total: 7.000992298126221 - average: 0.1093905046582222; Accuracy: 56.0\n",
      "Epoch 828 completed. Loss - total: 7.000988960266113 - average: 0.10939045250415802; Accuracy: 56.0\n",
      "Epoch 829 completed. Loss - total: 7.000986576080322 - average: 0.10939041525125504; Accuracy: 56.0\n",
      "Epoch 830 completed. Loss - total: 7.000983238220215 - average: 0.10939036309719086; Accuracy: 56.0\n",
      "Epoch 831 completed. Loss - total: 7.00098180770874 - average: 0.10939034074544907; Accuracy: 56.0\n",
      "Epoch 832 completed. Loss - total: 7.000978469848633 - average: 0.10939028859138489; Accuracy: 56.0\n",
      "Epoch 833 completed. Loss - total: 7.000976085662842 - average: 0.1093902513384819; Accuracy: 56.0\n",
      "Epoch 834 completed. Loss - total: 7.000972747802734 - average: 0.10939019918441772; Accuracy: 56.0\n",
      "Epoch 835 completed. Loss - total: 7.000969886779785 - average: 0.10939015448093414; Accuracy: 56.0\n",
      "Epoch 836 completed. Loss - total: 7.000967979431152 - average: 0.10939012467861176; Accuracy: 56.0\n",
      "Epoch 837 completed. Loss - total: 7.000965118408203 - average: 0.10939007997512817; Accuracy: 56.0\n",
      "Epoch 838 completed. Loss - total: 7.00096321105957 - average: 0.10939005017280579; Accuracy: 56.0\n",
      "Epoch 839 completed. Loss - total: 7.000959396362305 - average: 0.10938999056816101; Accuracy: 56.0\n",
      "Epoch 840 completed. Loss - total: 7.000957489013672 - average: 0.10938996076583862; Accuracy: 56.0\n",
      "Epoch 841 completed. Loss - total: 7.000955104827881 - average: 0.10938992351293564; Accuracy: 56.0\n",
      "Epoch 842 completed. Loss - total: 7.00095272064209 - average: 0.10938988626003265; Accuracy: 56.0\n",
      "Epoch 843 completed. Loss - total: 7.000949382781982 - average: 0.10938983410596848; Accuracy: 56.0\n",
      "Epoch 844 completed. Loss - total: 7.000947952270508 - average: 0.10938981175422668; Accuracy: 56.0\n",
      "Epoch 845 completed. Loss - total: 7.000945091247559 - average: 0.1093897670507431; Accuracy: 56.0\n",
      "Epoch 846 completed. Loss - total: 7.000943183898926 - average: 0.10938973724842072; Accuracy: 56.0\n",
      "Epoch 847 completed. Loss - total: 7.000940322875977 - average: 0.10938969254493713; Accuracy: 56.0\n",
      "Epoch 848 completed. Loss - total: 7.000937461853027 - average: 0.10938964784145355; Accuracy: 56.0\n",
      "Epoch 849 completed. Loss - total: 7.0009355545043945 - average: 0.10938961803913116; Accuracy: 56.0\n",
      "Epoch 850 completed. Loss - total: 7.0009331703186035 - average: 0.10938958078622818; Accuracy: 56.0\n",
      "Epoch 851 completed. Loss - total: 7.0009307861328125 - average: 0.1093895435333252; Accuracy: 56.0\n",
      "Epoch 852 completed. Loss - total: 7.000927925109863 - average: 0.10938949882984161; Accuracy: 56.0\n",
      "Epoch 853 completed. Loss - total: 7.0009260177612305 - average: 0.10938946902751923; Accuracy: 56.0\n",
      "Epoch 854 completed. Loss - total: 7.000924110412598 - average: 0.10938943922519684; Accuracy: 56.0\n",
      "Epoch 855 completed. Loss - total: 7.000921726226807 - average: 0.10938940197229385; Accuracy: 56.0\n",
      "Epoch 856 completed. Loss - total: 7.000919818878174 - average: 0.10938937216997147; Accuracy: 56.0\n",
      "Epoch 857 completed. Loss - total: 7.000916481018066 - average: 0.10938932001590729; Accuracy: 56.0\n",
      "Epoch 858 completed. Loss - total: 7.000915050506592 - average: 0.1093892976641655; Accuracy: 56.0\n",
      "Epoch 859 completed. Loss - total: 7.000912189483643 - average: 0.10938925296068192; Accuracy: 56.0\n",
      "Epoch 860 completed. Loss - total: 7.000910758972168 - average: 0.10938923060894012; Accuracy: 56.0\n",
      "Epoch 861 completed. Loss - total: 7.000907897949219 - average: 0.10938918590545654; Accuracy: 56.0\n",
      "Epoch 862 completed. Loss - total: 7.000905990600586 - average: 0.10938915610313416; Accuracy: 56.0\n",
      "Epoch 863 completed. Loss - total: 7.000903606414795 - average: 0.10938911885023117; Accuracy: 56.0\n",
      "Epoch 864 completed. Loss - total: 7.000901699066162 - average: 0.10938908904790878; Accuracy: 56.0\n",
      "Epoch 865 completed. Loss - total: 7.000898838043213 - average: 0.1093890443444252; Accuracy: 56.0\n",
      "Epoch 866 completed. Loss - total: 7.0008978843688965 - average: 0.10938902944326401; Accuracy: 56.0\n",
      "Epoch 867 completed. Loss - total: 7.0008955001831055 - average: 0.10938899219036102; Accuracy: 56.0\n",
      "Epoch 868 completed. Loss - total: 7.000893592834473 - average: 0.10938896238803864; Accuracy: 56.0\n",
      "Epoch 869 completed. Loss - total: 7.000891208648682 - average: 0.10938892513513565; Accuracy: 56.0\n",
      "Epoch 870 completed. Loss - total: 7.000888824462891 - average: 0.10938888788223267; Accuracy: 56.0\n",
      "Epoch 871 completed. Loss - total: 7.000886917114258 - average: 0.10938885807991028; Accuracy: 56.0\n",
      "Epoch 872 completed. Loss - total: 7.000885486602783 - average: 0.10938883572816849; Accuracy: 56.0\n",
      "Epoch 873 completed. Loss - total: 7.000883102416992 - average: 0.1093887984752655; Accuracy: 56.0\n",
      "Epoch 874 completed. Loss - total: 7.000881195068359 - average: 0.10938876867294312; Accuracy: 56.0\n",
      "Epoch 875 completed. Loss - total: 7.000879287719727 - average: 0.10938873887062073; Accuracy: 56.0\n",
      "Epoch 876 completed. Loss - total: 7.0008769035339355 - average: 0.10938870161771774; Accuracy: 56.0\n",
      "Epoch 877 completed. Loss - total: 7.000875473022461 - average: 0.10938867926597595; Accuracy: 56.0\n",
      "Epoch 878 completed. Loss - total: 7.000873565673828 - average: 0.10938864946365356; Accuracy: 56.0\n",
      "Epoch 879 completed. Loss - total: 7.000871658325195 - average: 0.10938861966133118; Accuracy: 56.0\n",
      "Epoch 880 completed. Loss - total: 7.0008697509765625 - average: 0.10938858985900879; Accuracy: 56.0\n",
      "Epoch 881 completed. Loss - total: 7.00086784362793 - average: 0.1093885600566864; Accuracy: 56.0\n",
      "Epoch 882 completed. Loss - total: 7.000866413116455 - average: 0.10938853770494461; Accuracy: 56.0\n",
      "Epoch 883 completed. Loss - total: 7.000864505767822 - average: 0.10938850790262222; Accuracy: 56.0\n",
      "Epoch 884 completed. Loss - total: 7.0008625984191895 - average: 0.10938847810029984; Accuracy: 56.0\n",
      "Epoch 885 completed. Loss - total: 7.000860691070557 - average: 0.10938844829797745; Accuracy: 56.0\n",
      "Epoch 886 completed. Loss - total: 7.000858306884766 - average: 0.10938841104507446; Accuracy: 56.0\n",
      "Epoch 887 completed. Loss - total: 7.000857353210449 - average: 0.10938839614391327; Accuracy: 56.0\n",
      "Epoch 888 completed. Loss - total: 7.000855445861816 - average: 0.10938836634159088; Accuracy: 56.0\n",
      "Epoch 889 completed. Loss - total: 7.000853538513184 - average: 0.1093883365392685; Accuracy: 56.0\n",
      "Epoch 890 completed. Loss - total: 7.000851631164551 - average: 0.1093883067369461; Accuracy: 56.0\n",
      "Epoch 891 completed. Loss - total: 7.000849723815918 - average: 0.10938827693462372; Accuracy: 56.0\n",
      "Epoch 892 completed. Loss - total: 7.000847816467285 - average: 0.10938824713230133; Accuracy: 56.0\n",
      "Epoch 893 completed. Loss - total: 7.0008463859558105 - average: 0.10938822478055954; Accuracy: 56.0\n",
      "Epoch 894 completed. Loss - total: 7.000844478607178 - average: 0.10938819497823715; Accuracy: 56.0\n",
      "Epoch 895 completed. Loss - total: 7.000843048095703 - average: 0.10938817262649536; Accuracy: 56.0\n",
      "Epoch 896 completed. Loss - total: 7.0008416175842285 - average: 0.10938815027475357; Accuracy: 56.0\n",
      "Epoch 897 completed. Loss - total: 7.0008392333984375 - average: 0.10938811302185059; Accuracy: 56.0\n",
      "Epoch 898 completed. Loss - total: 7.000837802886963 - average: 0.1093880906701088; Accuracy: 56.0\n",
      "Epoch 899 completed. Loss - total: 7.000836372375488 - average: 0.109388068318367; Accuracy: 56.0\n",
      "Epoch 900 completed. Loss - total: 7.000834941864014 - average: 0.10938804596662521; Accuracy: 56.0\n",
      "Epoch 901 completed. Loss - total: 7.000833511352539 - average: 0.10938802361488342; Accuracy: 56.0\n",
      "Epoch 902 completed. Loss - total: 7.000831604003906 - average: 0.10938799381256104; Accuracy: 56.0\n",
      "Epoch 903 completed. Loss - total: 7.000829219818115 - average: 0.10938795655965805; Accuracy: 56.0\n",
      "Epoch 904 completed. Loss - total: 7.000828266143799 - average: 0.10938794165849686; Accuracy: 56.0\n",
      "Epoch 905 completed. Loss - total: 7.000826835632324 - average: 0.10938791930675507; Accuracy: 56.0\n",
      "Epoch 906 completed. Loss - total: 7.00082540512085 - average: 0.10938789695501328; Accuracy: 56.0\n",
      "Epoch 907 completed. Loss - total: 7.000823497772217 - average: 0.10938786715269089; Accuracy: 56.0\n",
      "Epoch 908 completed. Loss - total: 7.000822067260742 - average: 0.1093878448009491; Accuracy: 56.0\n",
      "Epoch 909 completed. Loss - total: 7.000819683074951 - average: 0.10938780754804611; Accuracy: 56.0\n",
      "Epoch 910 completed. Loss - total: 7.000819206237793 - average: 0.10938780009746552; Accuracy: 56.0\n",
      "Epoch 911 completed. Loss - total: 7.00081729888916 - average: 0.10938777029514313; Accuracy: 56.0\n",
      "Epoch 912 completed. Loss - total: 7.0008158683776855 - average: 0.10938774794340134; Accuracy: 56.0\n",
      "Epoch 913 completed. Loss - total: 7.000814437866211 - average: 0.10938772559165955; Accuracy: 56.0\n",
      "Epoch 914 completed. Loss - total: 7.000813007354736 - average: 0.10938770323991776; Accuracy: 56.0\n",
      "Epoch 915 completed. Loss - total: 7.000810623168945 - average: 0.10938766598701477; Accuracy: 56.0\n",
      "Epoch 916 completed. Loss - total: 7.000809669494629 - average: 0.10938765108585358; Accuracy: 56.0\n",
      "Epoch 917 completed. Loss - total: 7.000808238983154 - average: 0.10938762873411179; Accuracy: 56.0\n",
      "Epoch 918 completed. Loss - total: 7.000807285308838 - average: 0.10938761383295059; Accuracy: 56.0\n",
      "Epoch 919 completed. Loss - total: 7.000805854797363 - average: 0.1093875914812088; Accuracy: 56.0\n",
      "Epoch 920 completed. Loss - total: 7.0008039474487305 - average: 0.10938756167888641; Accuracy: 56.0\n",
      "Epoch 921 completed. Loss - total: 7.000802993774414 - average: 0.10938754677772522; Accuracy: 56.0\n",
      "Epoch 922 completed. Loss - total: 7.000802040100098 - average: 0.10938753187656403; Accuracy: 56.0\n",
      "Epoch 923 completed. Loss - total: 7.000800132751465 - average: 0.10938750207424164; Accuracy: 56.0\n",
      "Epoch 924 completed. Loss - total: 7.000798225402832 - average: 0.10938747227191925; Accuracy: 56.0\n",
      "Epoch 925 completed. Loss - total: 7.000797748565674 - average: 0.10938746482133865; Accuracy: 56.0\n",
      "Epoch 926 completed. Loss - total: 7.000795364379883 - average: 0.10938742756843567; Accuracy: 56.0\n",
      "Epoch 927 completed. Loss - total: 7.000793933868408 - average: 0.10938740521669388; Accuracy: 56.0\n",
      "Epoch 928 completed. Loss - total: 7.000792980194092 - average: 0.10938739031553268; Accuracy: 56.0\n",
      "Epoch 929 completed. Loss - total: 7.000792026519775 - average: 0.10938737541437149; Accuracy: 56.0\n",
      "Epoch 930 completed. Loss - total: 7.000790119171143 - average: 0.1093873456120491; Accuracy: 56.0\n",
      "Epoch 931 completed. Loss - total: 7.000789165496826 - average: 0.10938733071088791; Accuracy: 56.0\n",
      "Epoch 932 completed. Loss - total: 7.000787734985352 - average: 0.10938730835914612; Accuracy: 56.0\n",
      "Epoch 933 completed. Loss - total: 7.000786781311035 - average: 0.10938729345798492; Accuracy: 56.0\n",
      "Epoch 934 completed. Loss - total: 7.000784873962402 - average: 0.10938726365566254; Accuracy: 56.0\n",
      "Epoch 935 completed. Loss - total: 7.000783920288086 - average: 0.10938724875450134; Accuracy: 56.0\n",
      "Epoch 936 completed. Loss - total: 7.000782489776611 - average: 0.10938722640275955; Accuracy: 56.0\n",
      "Epoch 937 completed. Loss - total: 7.000781536102295 - average: 0.10938721150159836; Accuracy: 56.0\n",
      "Epoch 938 completed. Loss - total: 7.00078010559082 - average: 0.10938718914985657; Accuracy: 56.0\n",
      "Epoch 939 completed. Loss - total: 7.000779151916504 - average: 0.10938717424869537; Accuracy: 56.0\n",
      "Epoch 940 completed. Loss - total: 7.000777721405029 - average: 0.10938715189695358; Accuracy: 56.0\n",
      "Epoch 941 completed. Loss - total: 7.000776290893555 - average: 0.10938712954521179; Accuracy: 56.0\n",
      "Epoch 942 completed. Loss - total: 7.0007758140563965 - average: 0.1093871220946312; Accuracy: 56.0\n",
      "Epoch 943 completed. Loss - total: 7.000773906707764 - average: 0.10938709229230881; Accuracy: 56.0\n",
      "Epoch 944 completed. Loss - total: 7.000772953033447 - average: 0.10938707739114761; Accuracy: 56.0\n",
      "Epoch 945 completed. Loss - total: 7.000771522521973 - average: 0.10938705503940582; Accuracy: 56.0\n",
      "Epoch 946 completed. Loss - total: 7.000770092010498 - average: 0.10938703268766403; Accuracy: 56.0\n",
      "Epoch 947 completed. Loss - total: 7.000769138336182 - average: 0.10938701778650284; Accuracy: 56.0\n",
      "Epoch 948 completed. Loss - total: 7.000768184661865 - average: 0.10938700288534164; Accuracy: 56.0\n",
      "Epoch 949 completed. Loss - total: 7.000766754150391 - average: 0.10938698053359985; Accuracy: 56.0\n",
      "Epoch 950 completed. Loss - total: 7.000765800476074 - average: 0.10938696563243866; Accuracy: 56.0\n",
      "Epoch 951 completed. Loss - total: 7.0007643699646 - average: 0.10938694328069687; Accuracy: 56.0\n",
      "Epoch 952 completed. Loss - total: 7.000762939453125 - average: 0.10938692092895508; Accuracy: 56.0\n",
      "Epoch 953 completed. Loss - total: 7.000761985778809 - average: 0.10938690602779388; Accuracy: 56.0\n",
      "Epoch 954 completed. Loss - total: 7.00076150894165 - average: 0.10938689857721329; Accuracy: 56.0\n",
      "Epoch 955 completed. Loss - total: 7.000759601593018 - average: 0.1093868687748909; Accuracy: 56.0\n",
      "Epoch 956 completed. Loss - total: 7.000758171081543 - average: 0.10938684642314911; Accuracy: 56.0\n",
      "Epoch 957 completed. Loss - total: 7.000757694244385 - average: 0.10938683897256851; Accuracy: 56.0\n",
      "Epoch 958 completed. Loss - total: 7.000756740570068 - average: 0.10938682407140732; Accuracy: 56.0\n",
      "Epoch 959 completed. Loss - total: 7.000755310058594 - average: 0.10938680171966553; Accuracy: 56.0\n",
      "Epoch 960 completed. Loss - total: 7.000754356384277 - average: 0.10938678681850433; Accuracy: 56.0\n",
      "Epoch 961 completed. Loss - total: 7.000753402709961 - average: 0.10938677191734314; Accuracy: 56.0\n",
      "Epoch 962 completed. Loss - total: 7.000751972198486 - average: 0.10938674956560135; Accuracy: 56.0\n",
      "Epoch 963 completed. Loss - total: 7.00075101852417 - average: 0.10938673466444016; Accuracy: 56.0\n",
      "Epoch 964 completed. Loss - total: 7.000750541687012 - average: 0.10938672721385956; Accuracy: 56.0\n",
      "Epoch 965 completed. Loss - total: 7.000749588012695 - average: 0.10938671231269836; Accuracy: 56.0\n",
      "Epoch 966 completed. Loss - total: 7.000748157501221 - average: 0.10938668996095657; Accuracy: 56.0\n",
      "Epoch 967 completed. Loss - total: 7.000747203826904 - average: 0.10938667505979538; Accuracy: 56.0\n",
      "Epoch 968 completed. Loss - total: 7.000746250152588 - average: 0.10938666015863419; Accuracy: 56.0\n",
      "Epoch 969 completed. Loss - total: 7.000744819641113 - average: 0.1093866378068924; Accuracy: 56.0\n",
      "Epoch 970 completed. Loss - total: 7.000743865966797 - average: 0.1093866229057312; Accuracy: 56.0\n",
      "Epoch 971 completed. Loss - total: 7.0007429122924805 - average: 0.10938660800457001; Accuracy: 56.0\n",
      "Epoch 972 completed. Loss - total: 7.000741958618164 - average: 0.10938659310340881; Accuracy: 56.0\n",
      "Epoch 973 completed. Loss - total: 7.000741004943848 - average: 0.10938657820224762; Accuracy: 56.0\n",
      "Epoch 974 completed. Loss - total: 7.000740051269531 - average: 0.10938656330108643; Accuracy: 56.0\n",
      "Epoch 975 completed. Loss - total: 7.000738620758057 - average: 0.10938654094934464; Accuracy: 56.0\n",
      "Epoch 976 completed. Loss - total: 7.000738620758057 - average: 0.10938654094934464; Accuracy: 56.0\n",
      "Epoch 977 completed. Loss - total: 7.000736713409424 - average: 0.10938651114702225; Accuracy: 56.0\n",
      "Epoch 978 completed. Loss - total: 7.000735759735107 - average: 0.10938649624586105; Accuracy: 56.0\n",
      "Epoch 979 completed. Loss - total: 7.000735282897949 - average: 0.10938648879528046; Accuracy: 56.0\n",
      "Epoch 980 completed. Loss - total: 7.000734329223633 - average: 0.10938647389411926; Accuracy: 56.0\n",
      "Epoch 981 completed. Loss - total: 7.000733375549316 - average: 0.10938645899295807; Accuracy: 56.0\n",
      "Epoch 982 completed. Loss - total: 7.000732421875 - average: 0.10938644409179688; Accuracy: 56.0\n",
      "Epoch 983 completed. Loss - total: 7.000731468200684 - average: 0.10938642919063568; Accuracy: 56.0\n",
      "Epoch 984 completed. Loss - total: 7.000730037689209 - average: 0.10938640683889389; Accuracy: 56.0\n",
      "Epoch 985 completed. Loss - total: 7.000729560852051 - average: 0.1093863993883133; Accuracy: 56.0\n",
      "Epoch 986 completed. Loss - total: 7.000728130340576 - average: 0.1093863770365715; Accuracy: 56.0\n",
      "Epoch 987 completed. Loss - total: 7.000728130340576 - average: 0.1093863770365715; Accuracy: 56.0\n",
      "Epoch 988 completed. Loss - total: 7.000726699829102 - average: 0.10938635468482971; Accuracy: 56.0\n",
      "Epoch 989 completed. Loss - total: 7.000726222991943 - average: 0.10938634723424911; Accuracy: 56.0\n",
      "Epoch 990 completed. Loss - total: 7.000725269317627 - average: 0.10938633233308792; Accuracy: 56.0\n",
      "Epoch 991 completed. Loss - total: 7.0007243156433105 - average: 0.10938631743192673; Accuracy: 56.0\n",
      "Epoch 992 completed. Loss - total: 7.000723361968994 - average: 0.10938630253076553; Accuracy: 56.0\n",
      "Epoch 993 completed. Loss - total: 7.000722885131836 - average: 0.10938629508018494; Accuracy: 56.0\n",
      "Epoch 994 completed. Loss - total: 7.000721454620361 - average: 0.10938627272844315; Accuracy: 56.0\n",
      "Epoch 995 completed. Loss - total: 7.000720500946045 - average: 0.10938625782728195; Accuracy: 56.0\n",
      "Epoch 996 completed. Loss - total: 7.0007195472717285 - average: 0.10938624292612076; Accuracy: 56.0\n",
      "Epoch 997 completed. Loss - total: 7.00071907043457 - average: 0.10938623547554016; Accuracy: 56.0\n",
      "Epoch 998 completed. Loss - total: 7.000718593597412 - average: 0.10938622802495956; Accuracy: 56.0\n",
      "Epoch 999 completed. Loss - total: 7.000717639923096 - average: 0.10938621312379837; Accuracy: 56.0\n",
      "Epoch 1000 completed. Loss - total: 7.000716209411621 - average: 0.10938619077205658; Accuracy: 56.0\n",
      "Training completed - final accuracy 56.0 and loss 7.000716209411621\n"
     ]
    }
   ],
   "source": [
    "loss, acc = train_model(model, trainloader, loss_fn, optimizer, num_epochs)\n",
    "print(f\"Training completed - final accuracy {acc} and loss {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[ 0.3047,  0.2600, -0.0881, -0.2216, -0.3213,  0.4201],\n",
       "                      [-0.3349,  0.1256, -0.3005,  0.3302,  0.4106,  0.1697]])),\n",
       "             ('layer1.bias', tensor([ 0.1375, -0.2310])),\n",
       "             ('layer2.weight', tensor([[-0.5246, -0.3130]])),\n",
       "             ('layer2.bias', tensor([-1.4803]))])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL virtualenv)",
   "language": "python",
   "name": "dssc_dl_2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}