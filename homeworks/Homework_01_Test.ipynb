{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "Provide the solutions to the homework either in (a) a Python script or (b) in a Jupyter notebook (preferred choice).\n",
    "\n",
    "Points 1, 2, 4 should be provided as code.\n",
    "\n",
    "Point 3 should be provided in a markdown cell (if Jupyter notebook) or in a multiline comment (if Python script).\n",
    "\n",
    "1. Taking inspiration from the notebook `01-intro-to-pt.ipynb`, build a class for the Multilayer Perceptron (MLP) whose scheme is drawn in the last figure of the notebook. As written there, no layer should have bias units and the activation for each hidden layer should be the Rectified Linear Unit (ReLU) function, also called ramp function. The activation leading to the output layer, instead, should be the softmax function, which prof. Ansuini explained during the last lecture. You can find some notions on it also on the notebook.                    \n",
    "\n",
    "\n",
    "2. After having defined the class, create an instance of it and print a summary using a method of your choice.\n",
    "\n",
    "\n",
    "3. Provide detailed calculations (layer-by-layer) on the exact number of parameters in the network.\n",
    "\n",
    "   1. Provide the same calculation in the case that the bias units are present in all layers (except input).\n",
    "   \n",
    "   \n",
    "4. For each layer within the MLP, calculate the L2 norm and L1 norm of its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us suppose we wish to build a larger model from the graph below.\n",
    "\n",
    "![](img/mlp_graph_larger.jpg)\n",
    "\n",
    "We suppose that\n",
    "\n",
    "1. The layers have no bias units\n",
    "2. The activation function for hidden layers is `ReLU`\n",
    "\n",
    "Moreover, we suppose that this is a classification problem.\n",
    "\n",
    "As you might recall, when the number of classes is > 2, we encode the problem in such a way that the output layer has a no. of neurons corresponding to the no. of classes. Doing so, we establish a correspondence between output units and classes. The value of the $j$-th neuron represents the **confidence** of the network in assigning a given data instance to the $j$-th class.\n",
    "\n",
    "Classically, when the network is encoded in such way, the activation function for the final layer is the **softmax** function.\n",
    "If $C$ is the total number of classes,\n",
    "\n",
    "$softmax(z_j) = \\frac{\\exp(z_j)}{\\sum_{k=1}^C \\exp(z_k)}$\n",
    "\n",
    "where $j\\in \\{1,\\cdots,C\\}$ is one of the classes.\n",
    "\n",
    "If we repeat this calculation for all $j$s, we end up with $C$ normalized values (i.e., between 0 and 1) which can be interpreted as probability that the network assigns the instance to the corresponding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(in_features =  5, out_features = 11, bias = False)\n",
    "        self.layer2 = torch.nn.Linear(in_features = 11, out_features = 16, bias = False)\n",
    "        self.layer3 = torch.nn.Linear(in_features = 16, out_features = 13, bias = False)\n",
    "        self.layer4 = torch.nn.Linear(in_features = 13, out_features = 8, bias = False)\n",
    "        self.layer5 = torch.nn.Linear(in_features =  8, out_features = 4, bias = False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.layer1(X)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.layer3(out)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.layer4(out)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.layer5(out)\n",
    "        out = torch.nn.functional.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layer1): Linear(in_features=5, out_features=11, bias=False)\n",
       "  (layer2): Linear(in_features=11, out_features=16, bias=False)\n",
       "  (layer3): Linear(in_features=16, out_features=13, bias=False)\n",
       "  (layer4): Linear(in_features=13, out_features=8, bias=False)\n",
       "  (layer5): Linear(in_features=8, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[ 0.3575, -0.1398, -0.4320, -0.4417, -0.3660],\n",
       "                      [-0.0365, -0.1304,  0.1207,  0.0152,  0.0177],\n",
       "                      [ 0.0810, -0.4347,  0.3170,  0.0636,  0.1497],\n",
       "                      [-0.3158, -0.3486,  0.1617,  0.1791, -0.3645],\n",
       "                      [ 0.2803, -0.3764, -0.3359,  0.3304, -0.2652],\n",
       "                      [ 0.2848, -0.2202,  0.1533,  0.0190,  0.4040],\n",
       "                      [-0.3167,  0.0412,  0.0585,  0.1546,  0.4256],\n",
       "                      [ 0.1684,  0.2240,  0.1046,  0.0644,  0.1343],\n",
       "                      [-0.0099, -0.1314, -0.4399,  0.2924, -0.1028],\n",
       "                      [-0.1140, -0.1220,  0.3910, -0.0302,  0.1748],\n",
       "                      [ 0.0529,  0.3622,  0.0514,  0.3865,  0.3588]])),\n",
       "             ('layer2.weight',\n",
       "              tensor([[-0.0064, -0.0029,  0.0103, -0.2114,  0.0764, -0.1479, -0.2010, -0.0172,\n",
       "                        0.0823, -0.1868, -0.2468],\n",
       "                      [ 0.0897, -0.0983,  0.2857, -0.0717, -0.2514, -0.1052,  0.2634,  0.1903,\n",
       "                        0.0013,  0.1246,  0.2195],\n",
       "                      [ 0.2925, -0.0054, -0.0713, -0.1751,  0.2603, -0.0019, -0.0745, -0.2005,\n",
       "                       -0.0656, -0.2124,  0.0426],\n",
       "                      [-0.0133, -0.2036, -0.1388, -0.2457, -0.1307,  0.2108, -0.1571, -0.0451,\n",
       "                       -0.1561,  0.2184,  0.1310],\n",
       "                      [-0.0970, -0.0041,  0.0175,  0.2830,  0.2541,  0.0791, -0.1435, -0.1586,\n",
       "                        0.2239,  0.2790, -0.2546],\n",
       "                      [-0.1997,  0.1617, -0.2987,  0.0320,  0.1543, -0.2394,  0.1306, -0.2287,\n",
       "                       -0.0447,  0.1363,  0.2042],\n",
       "                      [-0.0302,  0.2348, -0.2397, -0.0278,  0.1782,  0.2894, -0.0580, -0.1159,\n",
       "                        0.0485,  0.0569, -0.0953],\n",
       "                      [ 0.2623,  0.1396,  0.0909,  0.2176,  0.2031,  0.2132, -0.2567, -0.1398,\n",
       "                        0.0325,  0.1149,  0.0675],\n",
       "                      [ 0.2146, -0.2077, -0.2274, -0.2646, -0.2589,  0.2040, -0.0292, -0.1012,\n",
       "                       -0.0175, -0.0571,  0.1070],\n",
       "                      [ 0.2394,  0.0940,  0.0528,  0.0672,  0.0494,  0.0364,  0.2796, -0.0677,\n",
       "                        0.1478,  0.0972, -0.0457],\n",
       "                      [ 0.1039,  0.1711,  0.1239,  0.2983,  0.0278, -0.1278,  0.1317, -0.1551,\n",
       "                       -0.0932, -0.0174,  0.2521],\n",
       "                      [-0.0011, -0.2224,  0.1812, -0.1078,  0.2900,  0.2706, -0.0505, -0.2160,\n",
       "                       -0.1712, -0.0417, -0.2634],\n",
       "                      [ 0.1399,  0.1132,  0.0539,  0.0443, -0.2816,  0.1222,  0.0969,  0.1364,\n",
       "                        0.2838,  0.1278,  0.1936],\n",
       "                      [ 0.2735, -0.0910, -0.1948, -0.0015, -0.0455, -0.2525,  0.1855, -0.2943,\n",
       "                        0.2912, -0.2401, -0.2338],\n",
       "                      [ 0.1130,  0.1223, -0.0430, -0.2652, -0.0491,  0.1507,  0.2981,  0.2748,\n",
       "                        0.1746, -0.1067,  0.0426],\n",
       "                      [ 0.2025, -0.0879, -0.0725,  0.2132,  0.1780, -0.2256,  0.2912,  0.0019,\n",
       "                       -0.2078, -0.1350, -0.1147]])),\n",
       "             ('layer3.weight',\n",
       "              tensor([[-0.1202, -0.2296,  0.1215,  0.1793,  0.1583, -0.0122, -0.0150, -0.2318,\n",
       "                        0.0503, -0.0445, -0.0704,  0.0851, -0.1725,  0.0770, -0.2497, -0.1508],\n",
       "                      [ 0.2437,  0.0481,  0.1520,  0.2114,  0.1016,  0.1823,  0.0975, -0.2369,\n",
       "                       -0.2410,  0.2170, -0.1877, -0.1847, -0.1192, -0.0119, -0.1963, -0.1430],\n",
       "                      [ 0.1253,  0.0759, -0.0199, -0.1595,  0.1611, -0.1113, -0.0813,  0.0275,\n",
       "                        0.1622,  0.1014, -0.0114, -0.1287,  0.0303,  0.0751,  0.0323,  0.1537],\n",
       "                      [-0.2182, -0.0058,  0.1134,  0.0749,  0.1397, -0.0926,  0.2296,  0.2172,\n",
       "                       -0.0865,  0.2293,  0.0395,  0.2057, -0.0899,  0.0439,  0.1899, -0.1465],\n",
       "                      [ 0.0241, -0.1386,  0.0716,  0.2044,  0.2254, -0.1681, -0.2318, -0.1176,\n",
       "                       -0.1605, -0.1146, -0.1354, -0.1802,  0.1624,  0.0976, -0.1739, -0.1609],\n",
       "                      [-0.1255, -0.1408, -0.1844, -0.1293, -0.2317,  0.0518, -0.2117, -0.0649,\n",
       "                       -0.0867, -0.1599,  0.2455,  0.1249, -0.0580, -0.2102,  0.0303,  0.0650],\n",
       "                      [ 0.2332,  0.1822, -0.2043, -0.0548, -0.2425,  0.1209,  0.1571, -0.1013,\n",
       "                        0.0885, -0.0205, -0.0079, -0.1587,  0.0511,  0.1404, -0.0303,  0.1228],\n",
       "                      [-0.0762, -0.1634,  0.1719,  0.0602,  0.0539,  0.2448,  0.1333, -0.2139,\n",
       "                       -0.0850, -0.0432, -0.1669,  0.1545,  0.0659, -0.0751,  0.1117,  0.0364],\n",
       "                      [ 0.2086,  0.2307,  0.0191, -0.0384,  0.1793,  0.2424,  0.1750,  0.0412,\n",
       "                       -0.2259,  0.2258, -0.1747, -0.0444, -0.1436,  0.1675,  0.0978, -0.0260],\n",
       "                      [-0.0758,  0.1097, -0.2410,  0.0284,  0.1579, -0.0735,  0.0489, -0.2062,\n",
       "                        0.0621,  0.0546, -0.1448,  0.2223, -0.0104,  0.0564, -0.0306, -0.2116],\n",
       "                      [-0.1820, -0.0310,  0.2477,  0.1194, -0.1295,  0.0094,  0.1459, -0.1752,\n",
       "                        0.1069,  0.0509, -0.2155, -0.2235, -0.2195,  0.1903, -0.0959,  0.1975],\n",
       "                      [ 0.1298, -0.1373,  0.2454, -0.0873, -0.0267, -0.1921, -0.0094,  0.0250,\n",
       "                       -0.1609, -0.1191, -0.0014,  0.1805, -0.0860, -0.1026,  0.1314, -0.0313],\n",
       "                      [ 0.1941,  0.2066, -0.2026, -0.0326, -0.2303, -0.2049,  0.0792, -0.2333,\n",
       "                       -0.0167, -0.1863, -0.2390,  0.2093,  0.1675, -0.0231,  0.2003,  0.2232]])),\n",
       "             ('layer4.weight',\n",
       "              tensor([[-0.2567, -0.0644, -0.1416, -0.1397, -0.1368, -0.2325,  0.0438, -0.0702,\n",
       "                       -0.2726, -0.2127, -0.0707,  0.1749, -0.1378],\n",
       "                      [ 0.1655,  0.0567, -0.1724, -0.0487,  0.0090, -0.2645, -0.0545,  0.1210,\n",
       "                       -0.2449,  0.2648,  0.1312, -0.1637, -0.1307],\n",
       "                      [ 0.2374,  0.1473,  0.1865,  0.0074,  0.0967,  0.1302, -0.0380, -0.2160,\n",
       "                       -0.1351, -0.0784,  0.2628, -0.1284,  0.1667],\n",
       "                      [-0.1117, -0.2131, -0.2115,  0.0151, -0.1944,  0.1804,  0.0369, -0.1780,\n",
       "                        0.1430,  0.2070, -0.2721, -0.2506,  0.1924],\n",
       "                      [ 0.1253, -0.0489,  0.2750, -0.0127, -0.1631,  0.2714,  0.0991, -0.0012,\n",
       "                       -0.0029, -0.1390,  0.1008, -0.1436, -0.2610],\n",
       "                      [ 0.2617, -0.1865,  0.0741,  0.0830, -0.0427, -0.1893, -0.2585,  0.1299,\n",
       "                        0.1357,  0.0604,  0.1756,  0.2612,  0.1488],\n",
       "                      [-0.0736,  0.0556, -0.1006, -0.2572, -0.0330, -0.1220,  0.0632,  0.2400,\n",
       "                       -0.1351,  0.1398,  0.2168,  0.2523, -0.0176],\n",
       "                      [-0.1324,  0.0845, -0.2517, -0.0143, -0.1862,  0.1811, -0.1313,  0.1087,\n",
       "                       -0.0499, -0.0335,  0.0039,  0.0689,  0.1858]])),\n",
       "             ('layer5.weight',\n",
       "              tensor([[ 0.1368,  0.2557,  0.0623,  0.0185, -0.1356, -0.3075,  0.0247,  0.2958],\n",
       "                      [ 0.2162,  0.3026,  0.1669,  0.3300, -0.2126,  0.3196,  0.0416, -0.2903],\n",
       "                      [ 0.0585,  0.2909,  0.2737, -0.2430, -0.1278,  0.0838, -0.1249,  0.2962],\n",
       "                      [-0.2434, -0.1771, -0.1624,  0.1048, -0.2506, -0.1784,  0.3096,  0.3164]]))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Linear: 1-1                            55\n",
      "├─Linear: 1-2                            176\n",
      "├─Linear: 1-3                            208\n",
      "├─Linear: 1-4                            104\n",
      "├─Linear: 1-5                            32\n",
      "=================================================================\n",
      "Total params: 575\n",
      "Trainable params: 575\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "_ = summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(obj, title=None):\n",
    "    if title is not None:\n",
    "        print(title)\n",
    "    print(obj)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (covariates)\n",
      "tensor([[ 0.2183, -0.0832, -0.1295,  0.0803,  0.1045],\n",
      "        [ 1.0737,  0.9031,  0.3763,  1.1204,  0.5320],\n",
      "        [ 2.0429,  1.7837,  1.9326,  2.2841,  2.0563],\n",
      "        [ 2.8074,  2.8198,  3.3179,  2.7253,  3.1570],\n",
      "        [ 3.9642,  3.8509,  4.5325,  4.3087,  4.1998],\n",
      "        [ 4.9211,  5.0005,  4.5771,  5.3332,  4.9440],\n",
      "        [ 5.8898,  6.2374,  6.3189,  6.3029,  6.0736],\n",
      "        [ 7.4177,  7.2779,  6.7890,  6.9428,  6.7353],\n",
      "        [ 8.4458,  8.0981,  7.8257,  7.9372,  8.1026],\n",
      "        [ 8.8283,  8.5995,  9.3828,  9.3346,  9.1644]])\n",
      "\n",
      "\n",
      "y (response)\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela/Documenti/Deep Learning/DSSC_DL_2021/venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/angela/Documenti/Deep Learning/DSSC_DL_2021/venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  \n",
      "/home/angela/Documenti/Deep Learning/DSSC_DL_2021/venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/angela/Documenti/Deep Learning/DSSC_DL_2021/venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  after removing the cwd from sys.path.\n",
      "/home/angela/Documenti/Deep Learning/DSSC_DL_2021/venv/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  \"\"\"\n",
      "/home/angela/Documenti/Deep Learning/DSSC_DL_2021/venv/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.range(0, 9).unsqueeze(-1)\n",
    "x2 = torch.range(0, 9).unsqueeze(-1)\n",
    "x3 = torch.range(0, 9).unsqueeze(-1)\n",
    "x4 = torch.range(0, 9).unsqueeze(-1)\n",
    "x5 = torch.range(0, 9).unsqueeze(-1)\n",
    "X = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "eps = torch.normal(0, .3, (10, 5))\n",
    "X += eps\n",
    "\n",
    "y = torch.range(0, 9).unsqueeze(-1)\n",
    "\n",
    "\n",
    "pretty_print(X, \"X (covariates)\")\n",
    "pretty_print(y, \"y (response)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regressor predictions\n",
      "tensor([[0.2490, 0.2512, 0.2504, 0.2494],\n",
      "        [0.2492, 0.2520, 0.2501, 0.2486],\n",
      "        [0.2463, 0.2591, 0.2489, 0.2457],\n",
      "        [0.2441, 0.2644, 0.2478, 0.2437],\n",
      "        [0.2420, 0.2698, 0.2470, 0.2412],\n",
      "        [0.2415, 0.2717, 0.2473, 0.2395],\n",
      "        [0.2389, 0.2781, 0.2459, 0.2371],\n",
      "        [0.2384, 0.2793, 0.2465, 0.2358],\n",
      "        [0.2359, 0.2854, 0.2455, 0.2332],\n",
      "        [0.2329, 0.2930, 0.2434, 0.2307]], grad_fn=<SoftmaxBackward>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela/Documenti/Deep Learning/DSSC_DL_2021/venv/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(X)\n",
    "pretty_print(y_hat, \"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    # Assign each y_hat to its predicted class\n",
    "    pred_classes = torch.where(y_hat < .5, 0, 1).squeeze().long()\n",
    "    correct = (pred_classes == y).sum()\n",
    "    return (correct / y.shape[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4000000059604645"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first layer we have $5 * 11 = 55$ parameters, in the second one $11 * 16 = 176$, in the third one $16 * 13 = 208$, in the fourth one $13 * 8 = 104$, and in the fifth one $8 * 4 = 32$, so in total we have $575$ parameters.\n",
    "\n",
    "If we include also the bias, then in the first layer we have $(5 + 1) * 11 = 66$ parameters, in the second one $(11 + 1) * 16 = 192$, in the third one $(16 + 1) * 13 = 221$, in the fourth one $(13 + 1) * 8 = 112$, and in the fifth one $(8 + 1) * 4 = 36$, so in total we have $627$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation of the L1 norm of the parameters:\n",
      "Layer 0 has norm 2.763221263885498\n",
      "Layer 1 has norm 2.6886987686157227\n",
      "Layer 2 has norm 2.1026058197021484\n",
      "Layer 3 has norm 1.5712890625\n",
      "Layer 4 has norm 1.1986228227615356\n"
     ]
    }
   ],
   "source": [
    "print('Computation of the L1 norm of the parameters:')\n",
    "for n, i in enumerate(model.state_dict().items()):\n",
    "    print(f'Layer {n} has norm {torch.linalg.norm(i[1], 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation of the L2 norm of the parameters:\n",
      "Layer 0 has norm 1.227863073348999\n",
      "Layer 1 has norm 1.0856382846832275\n",
      "Layer 2 has norm 1.0596067905426025\n",
      "Layer 3 has norm 0.853816032409668\n",
      "Layer 4 has norm 0.8204464912414551\n"
     ]
    }
   ],
   "source": [
    "print('Computation of the L2 norm of the parameters:')\n",
    "for n, i in enumerate(model.state_dict().items()):\n",
    "    print(f'Layer {n} has norm {torch.linalg.norm(i[1], 2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL virtualenv)",
   "language": "python",
   "name": "dssc_dl_2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
